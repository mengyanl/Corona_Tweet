{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a853f227",
   "metadata": {},
   "source": [
    "# SpringBoard Capstone2: Coronavirus Tweets\n",
    "\n",
    "    Data from Kaggle.com: https://www.kaggle.com/datatattle/covid-19-nlp-text-classification/metadata\n",
    "## Data Explore and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3eb16dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b9c60dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/Ling/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da11a325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# from wordcloud import WordCloud\n",
    "import re\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fff5c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41157 entries, 3799 to 44955\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   ScreenName     41157 non-null  int64 \n",
      " 1   Location       32567 non-null  object\n",
      " 2   TweetAt        41157 non-null  object\n",
      " 3   OriginalTweet  41157 non-null  object\n",
      " 4   Sentiment      41157 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 1.9+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3798 entries, 1 to 3798\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   ScreenName     3798 non-null   int64 \n",
      " 1   Location       2964 non-null   object\n",
      " 2   TweetAt        3798 non-null   object\n",
      " 3   OriginalTweet  3798 non-null   object\n",
      " 4   Sentiment      3798 non-null   object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 178.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "tweet_whole_train = pd.read_csv('/Users/Ling/Desktop/01_Springboard/Corona_Tweet/Data/Corona_NLP_train.csv', index_col = 0)\n",
    "print(tweet_whole_train.info())\n",
    "test = pd.read_csv('/Users/Ling/Desktop/01_Springboard/Corona_Tweet/Data/Corona_NLP_test.csv', index_col = 0)\n",
    "print(test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b4021ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ScreenName   Location     TweetAt  \\\n",
      "UserName                                      \n",
      "3799           48751     London  16-03-2020   \n",
      "3800           48752         UK  16-03-2020   \n",
      "3801           48753  Vagabonds  16-03-2020   \n",
      "3802           48754        NaN  16-03-2020   \n",
      "3803           48755        NaN  16-03-2020   \n",
      "\n",
      "                                              OriginalTweet  \\\n",
      "UserName                                                      \n",
      "3799      @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...   \n",
      "3800      advice Talk to your neighbours family to excha...   \n",
      "3801      Coronavirus Australia: Woolworths to give elde...   \n",
      "3802      My food stock is not the only one which is emp...   \n",
      "3803      Me, ready to go at supermarket during the #COV...   \n",
      "\n",
      "                   Sentiment  \n",
      "UserName                      \n",
      "3799                 Neutral  \n",
      "3800                Positive  \n",
      "3801                Positive  \n",
      "3802                Positive  \n",
      "3803      Extremely Negative  \n"
     ]
    }
   ],
   "source": [
    "print(tweet_whole_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec1748d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = tweet_whole_train[['OriginalTweet', 'Sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "759dc8fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(tweet.isnull().any(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f91e5808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Extremely Negative', 'Extremely Positive', 'Negative', 'Neutral',\n",
       "        'Positive'], dtype=object),\n",
       " array([ 5481,  6624,  9917,  7713, 11422]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(tweet.Sentiment, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98a6ab57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAFfCAYAAABk9EqQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAiO0lEQVR4nO3de7hcVX3/8ffHBLmaChKsJghIg/4CKpcUwUu94KNoq1ALFVsuKjX+FC1WayFqQVupWqtWqGDxRtAqpGoV+hMtjaKtcjFBJAIiURQiFIJSiRdA4uf3x17HDIfJySQ7Z6+ZzOf1PPPMzJrZM98zTzKf2XutvZZsExERsakeVLuAiIgYbQmSiIhoJUESERGtJEgiIqKVBElERLSSIImIiFZm1i6gazvvvLN333332mVERIyU5cuX32F7dr/Hxi5Idt99d5YtW1a7jIiIkSLph+t7LIe2IiKilQRJRES0kiCJiIhWEiQREdFKgiQiIlpJkERERCsJkoiIaCVBEhERrYzdCYkRsem+8ntPq13CZve0r36ldgkjL3skERHRSoIkIiJaSZBEREQrCZKIiGglQRIREa0kSCIiopUESUREtJIgiYiIVhIkERHRSoIkIiJaSZBEREQrCZKIiGglQRIREa0kSCIiopUESUREtJIgiYiIVhIkERHRSoIkIiJaSZBEREQrCZKIiGglQRIREa1MW5BI+oik2yV9u6dtJ0kXS7qhXO/Y89giSSslXS/pOT3tB0haUR47XZJK+9aSzi/tl0vafbr+loiIWL/p3CM5Bzh0UtvJwFLb84Cl5T6S5gNHAXuXbc6UNKNscxawEJhXLhOveTxwp+3fAd4LvHPa/pKIiFivaQsS218FfjKp+TBgcbm9GDi8p/082/fYvhFYCRwo6RHALNuX2jZw7qRtJl7rU8AhE3srERHRna77SB5u+1aAcr1LaZ8D3NzzvFWlbU65Pbn9ftvYvg/4KfCwaas8IiL6GpbO9n57Ep6ifaptHvji0kJJyyQtW7169SaWGBER/XQdJLeVw1WU69tL+ypg157nzQVuKe1z+7TfbxtJM4Hf4oGH0gCwfbbtBbYXzJ49ezP9KRERATCz4/e7ADgOeEe5/lxP+yckvQd4JE2n+hW210paI+kg4HLgWOCMSa91KXAE8KXSjxKbwU1/87jaJWx2jzplRe0SIrZI0xYkkj4JPB3YWdIq4FSaAFki6XjgJuBIANvXSFoCXAvcB5xge215qVfSjADbFrioXAA+DHxM0kqaPZGjputviYiI9Zu2ILH94vU8dMh6nn8acFqf9mXAPn3a76YEUURE1DMsne0RETGiEiQREdFKgiQiIlpJkERERCsJkoiIaCVBEhERrSRIIiKilQRJRES0kiCJiIhWEiQREdFKgiQiIlpJkERERCsJkoiIaCVBEhERrSRIIiKilQRJRES0kiCJiIhWEiQREdFKgiQiIlpJkERERCsJkoiIaCVBEhERrSRIIiKilQRJRES0kiCJiIhWEiQREdFKgiQiIlpJkERERCtVgkTSX0i6RtK3JX1S0jaSdpJ0saQbyvWOPc9fJGmlpOslPaen/QBJK8pjp0tSjb8nImKcdR4kkuYAfw4ssL0PMAM4CjgZWGp7HrC03EfS/PL43sChwJmSZpSXOwtYCMwrl0M7/FMiIoJ6h7ZmAttKmglsB9wCHAYsLo8vBg4vtw8DzrN9j+0bgZXAgZIeAcyyfaltA+f2bBMRER3pPEhs/wj4B+Am4Fbgp7b/A3i47VvLc24FdimbzAFu7nmJVaVtTrk9uf0BJC2UtEzSstWrV2/OPyciYuzVOLS1I81exh7AI4HtJR091SZ92jxF+wMb7bNtL7C9YPbs2RtbckRETKHGoa1nATfaXm37V8BngCcBt5XDVZTr28vzVwG79mw/l+ZQ2Kpye3J7RER0qEaQ3AQcJGm7MsrqEOA64ALguPKc44DPldsXAEdJ2lrSHjSd6leUw19rJB1UXufYnm0iIqIjM7t+Q9uXS/oUcCVwH/BN4GxgB2CJpONpwubI8vxrJC0Bri3PP8H22vJyrwTOAbYFLiqXiIjoUOdBAmD7VODUSc330Oyd9Hv+acBpfdqXAfts9gIjejz5jCfXLmGz+9prvla7hNiC5Mz2iIhoJUESERGtJEgiIqKVBElERLSSIImIiFYSJBER0UqCJCIiWkmQREREKwmSiIhoJUESERGtJEgiIqKVBElERLSSIImIiFYSJBER0UqCJCIiWkmQREREKwmSiIhoJUESERGtJEgiIqKVgdZsl7TU9iEbaouIGBf/9PoLa5ew2b363c/fpO2mDBJJ2wDbATtL2hFQeWgW8MhNeseIiNiibGiP5BXAa2lCYznrguQu4P3TV1ZERIyKKYPE9vuA90l6je0zOqopIiJGyEB9JLbPkPQkYPfebWyfO011RUTEiBi0s/1jwJ7AVcDa0mwgQRIRMeYGChJgATDftqezmIiIGD2DnkfybeC3p7OQiIgYTYMGyc7AtZK+KOmCicumvqmkh0r6lKTvSLpO0sGSdpJ0saQbyvWOPc9fJGmlpOslPaen/QBJK8pjp0tS/3eMiIjpMuihrbds5vd9H/AF20dIejDNuSpvBJbafoekk4GTgZMkzQeOAvamGYb8n5L2sr0WOAtYCFwGfB44FLhoM9caERFTGHTU1lc21xtKmgX8HvCS8tr3AvdKOgx4ennaYuAS4CTgMOA82/cAN0paCRwo6QfALNuXltc9FzicBElERKcGOrQlaY2ku8rlbklrJd21ie/5aGA18FFJ35T0IUnbAw+3fStAud6lPH8OcHPP9qtK25xye3J7RER0aKAgsf0Q27PKZRvgj4B/2sT3nAnsD5xlez/g5zSHsdanX7+Hp2h/4AtICyUtk7Rs9erVG1tvRERMYZNm/7X9WeCZm/ieq4BVti8v9z9FEyy3SXoEQLm+vef5u/ZsPxe4pbTP7dPer96zbS+wvWD27NmbWHZERPQz6AmJL+y5+yCa80o26ZwS2/8j6WZJj7F9PXAIcG25HAe8o1x/rmxyAfAJSe+h6WyfB1xhe2055HYQcDlwLJBpXCIiOjboqK3euYXvA35A0wm+qV4D/EsZsfV94KU0AbVE0vHATcCRALavkbSEJmjuA04oI7YAXgmcA2xL08mejvaIiI4NOmrrpZvzTW1fRbNXM1nf9U1snwac1qd9GbDP5qwtIiI2zqCjtuZK+jdJt0u6TdKnJc3d8JYREbGlG7Sz/aM0fRWPpBlie2Fpi4iIMTdokMy2/VHb95XLOUCGP0VExMBBcoekoyXNKJejgR9PZ2ERETEaBh219TKaExDfSzPs9+s0I622KAe8YctbXmX5u46tXUJEbOEGDZK/BY6zfSeApJ2Af6AJmIiIGGODHtp6/ESIANj+CbDf9JQUERGjZNAgedCk9UF2YvC9mYiI2IINGgbvBr4u6VM0fSR/TJ8TBCMiYvwMemb7uZKW0UzUKOCFtq+d1soiImIkDHx4qgRHwiMiIu5nk6aRj4iImJAgiYiIVhIkERHRSoIkIiJaSZBEREQrCZKIiGglQRIREa0kSCIiopUESUREtJIgiYiIVhIkERHRSoIkIiJaSZBEREQrCZKIiGglQRIREa0kSCIiopVqQSJphqRvSvr3cn8nSRdLuqFc964Rv0jSSknXS3pOT/sBklaUx06XpBp/S0TEOKu5R3IicF3P/ZOBpbbnAUvLfSTNB44C9gYOBc6UNKNscxawEJhXLod2U3pEREyoEiSS5gK/D3yop/kwYHG5vRg4vKf9PNv32L4RWAkcKOkRwCzbl9o2cG7PNhER0ZFaeyT/CPwV8OuetofbvhWgXO9S2ucAN/c8b1Vpm1NuT26PiIgOdR4kkv4AuN328kE36dPmKdr7vedCScskLVu9evWAbxsREYOosUfyZOAFkn4AnAc8U9LHgdvK4SrK9e3l+auAXXu2nwvcUtrn9ml/ANtn215ge8Hs2bM3598SETH2Og8S24tsz7W9O00n+pdsHw1cABxXnnYc8Lly+wLgKElbS9qDplP9inL4a42kg8porWN7tomIiI7MrF1Aj3cASyQdD9wEHAlg+xpJS4BrgfuAE2yvLdu8EjgH2Ba4qFwiIqJDVYPE9iXAJeX2j4FD1vO804DT+rQvA/aZvgojImJDcmZ7RES0kiCJiIhWEiQREdFKgiQiIlpJkERERCsJkoiIaCVBEhERrSRIIiKilQRJRES0kiCJiIhWEiQREdFKgiQiIlpJkERERCsJkoiIaCVBEhERrSRIIiKilQRJRES0kiCJiIhWEiQREdFKgiQiIlpJkERERCsJkoiIaCVBEhERrSRIIiKilQRJRES0kiCJiIhWEiQREdFK50EiaVdJX5Z0naRrJJ1Y2neSdLGkG8r1jj3bLJK0UtL1kp7T036ApBXlsdMlqeu/JyJi3NXYI7kPeL3t/wMcBJwgaT5wMrDU9jxgablPeewoYG/gUOBMSTPKa50FLATmlcuhXf4hERFRIUhs32r7ynJ7DXAdMAc4DFhcnrYYOLzcPgw4z/Y9tm8EVgIHSnoEMMv2pbYNnNuzTUREdKRqH4mk3YH9gMuBh9u+FZqwAXYpT5sD3Nyz2arSNqfcntweEREdqhYkknYAPg281vZdUz21T5unaO/3XgslLZO0bPXq1RtfbERErFeVIJG0FU2I/Ivtz5Tm28rhKsr17aV9FbBrz+ZzgVtK+9w+7Q9g+2zbC2wvmD179ub7QyIiosqoLQEfBq6z/Z6ehy4Ajiu3jwM+19N+lKStJe1B06l+RTn8tUbSQeU1j+3ZJiIiOjKzwns+GTgGWCHpqtL2RuAdwBJJxwM3AUcC2L5G0hLgWpoRXyfYXlu2eyVwDrAtcFG5REREhzoPEtv/Tf/+DYBD1rPNacBpfdqXAftsvuoiImJj5cz2iIhoJUESERGtJEgiIqKVBElERLSSIImIiFYSJBER0UqCJCIiWkmQREREKwmSiIhoJUESERGtJEgiIqKVBElERLSSIImIiFYSJBER0UqCJCIiWkmQREREKwmSiIhoJUESERGtJEgiIqKVBElERLSSIImIiFYSJBER0UqCJCIiWkmQREREKwmSiIhoJUESERGtJEgiIqKVBElERLQy8kEi6VBJ10taKenk2vVERIybkQ4SSTOA9wPPBeYDL5Y0v25VERHjZaSDBDgQWGn7+7bvBc4DDqtcU0TEWJHt2jVsMklHAIfa/rNy/xjgibZfPel5C4GF5e5jgOs7LbS/nYE7ahcxJPJZNPI5rJPPYp1h+Sx2sz273wMzu65kM1Oftgcko+2zgbOnv5zBSVpme0HtOoZBPotGPod18lmsMwqfxagf2loF7Npzfy5wS6VaIiLG0qgHyTeAeZL2kPRg4Cjggso1RUSMlZE+tGX7PkmvBr4IzAA+YvuaymUNaqgOtVWWz6KRz2GdfBbrDP1nMdKd7RERUd+oH9qKiIjKEiQREdFKgiQiIlpJkHRE0l6Slkr6drn/eElvrl1XRAwXNY6WdEq5/yhJB9auayoJku58EFgE/ArA9tU0w5XHlqTdJD2r3N5W0kNq19QVSTtNdaldXw35sfUbZwIHAy8u99fQzCk4tEZ6+O+I2c72FdL9Tsa/r1YxtUl6Oc20NTsBe9KcTPoB4JCadXVoOc0sDOubneHR3ZYzFD4IvAH4Z2h+bEn6BPC2qlV174m295f0TQDbd5bz5IZWgqQ7d0jakzKFS5kn7Na6JVV1As2km5cD2L5B0i51S+qO7T1q1zCE8mOr8asys/nEd8Vs4Nd1S5pagqQ7J9CcWPRYST8CbgT+tG5JVd1j+96JLw1JM+kzT9o4kLQjMA/YZqLN9lfrVVRNfmw1Tgf+DdhF0mnAEcBQH+LLCYkdkTTD9lpJ2wMPsr2mdk01Sfp74H+BY4HXAK8CrrX9ppp1dU3SnwEn0hzauwo4CLjU9jNr1lWDpEfT/Nh6EnAn5ceW7R9WLawCSY+lOcwrYKnt6yqXNKUESUck3QR8ATgf+JLH/IOX9CDgeODZNP9Zvgh8aNw+F0krgN8FLrO9b/kCeavtF1UurXP5sdWQ9D7gfNtfr13LoDJqqzuPAf6T5hDXjZL+SdJTKtdU02HAubaPtH2E7Q+OW4gUd9u+G0DS1ra/Q/NvZRzdKOlsmr2yn9UupqIrgTeX5cPfJWmop5CHBElnbP/S9hLbLwT2A2YBX6lcVk0vAL4r6WOSfr/0kYyjVZIeCnwWuFjS5xjfpRDyYwuwvdj282gGo3wXeKekGyqXNaUc2uqQpKcBL6JZY/4bNLuvn65bVT2StqL5LF4EPAW4eGK1y3FU/n38FvCFsnT02CoDEN5H00cyo3Y9NZSTEF8EHE7Tf/j8uhWtX4KkI5JupOlMXQJcYPvndSsaDiVMDgVeCjx1fUt5bolKP9HVtvepXcuwyI8tkPRO4IXA92i+Lz5j+3+rFrUB43o4oYYn2L6rdhHDQtKhNGf2PwO4BPgQ8Mc1a+qa7V9L+pakR9m+qXY9tU36sfWGMf6xdSNwsO1hWKd9INkjmWaS/sr230s6g/7ryf95hbKqk3QecB5wke17atdTi6Qv0YzaugL4zRen7RdUK6oSSbPG+ceWpMfa/o6k/fs9bvvKrmsaVPZIpt/E+O9lVasYMrbHep6xHm+tXUBtEz+2gNMkjfOPrdfRTBv07j6PGRjac4sSJNPM9oXl5i9s/2vvY5KOrFBSVZL+2/ZTJK3h/ntoAmx7VqXSanme7ZN6G8ox8nEa0ZcfW4DtheXmcyeGhE+QtE2fTYZGDm11RNKVtvffUFuMl/X8u7ja9uNr1VSLpCP7/dia3LalG8XviuyRTDNJzwWeB8yRdHrPQ7MYzwnpAJD0MdvHbKhtSyXplTTTwuwp6eqehx4CjMwZzZvZImByaPRr2yJJ+m1gDrCtpP1YNzP0LGC7aoUNIEEy/W6h2WV/Ac3U4RPWAH9RpaLhsHfvnXJC4gGVaqnhE8BFwNuBk3va19j+SZ2S6siPrd94DvASmnnX3tPTvgZ4Y42CBpVDWx2RtJXtX9WuozZJi2j+U2wL/GKiGbgXONv2olq11SDpUf3ax2k4sKQnAPsCfwOc0vPQGuDLtu+sUVctkv5o1M6dSZB0RNI8ml+f87n/dOHjuIARkt4+bqHRT5m0cWKBq22APYDrbe895YZbIEkzbY/THsj9SDra9sclvZ7+pwq8p89mQyGHtrrzUeBU4L00J+G9lP6r440F24uyDgfYflzv/XIOwSsqlVOFpCW2/xj45qThvxMj+cZl4MH25XqHqlVsguyRdETSctsHSFox8eUh6b9sP7V2bTVkHY71G/YROpubpEfYvlXSbv0eH8f1SEZN9ki6c3eZW+kGSa8GfgSMzdKyfZzIunU4njGxDkflmjon6XU9dx8E7A+srlROFbYnVkG8A/hlmTpmL+CxNAMSxkpZ9O1twC9p1jB6AvBa2x+vWtgUMo18d15LM4Tvz2lGJx0DHFezoMqyDkfjIT2XrYH/R7NWyzj6KrCNpDnAUprDv+dUraiOZ5epYv4AWAXsBbyhbklTyx5JR2x/o9z8Gc1/kHE3eR2OOxnDdThsvxVA0vZjPEnhBNn+haTjgTPKHHXfrF1UBVuV6+cBn7T9E2m4u1MTJB2RdCEPHInxU5pzTP558pQIWzrbf1huvkXSlynrcFQsqQpJBwMfpulgfVQZCvsK26+qW1kVKp/Hn9Iswwzj+R11oaTv0BzaepWk2cBQfz+ks70jZR3m2cAnS9OLgP+hOZ9i1ric0T1B0k59mteM27k2ki4HjqBZo2a/0vbtcVyjpKxF8nrga7bfKenRNH0D4zJp42+UEY13lTXst6P5jvif2nWtT4KkI5K+avv3+rVJumbczhuQ9ANgV+BOmmGeDwVuBW4HXm57+Xo33oJIutz2EyV9sydIvmX7CbVrq0XSQ2iG/Y7luu1lsbdXAhPfF18BPjDMP7LS2d6d2b1nMZfbO5e747is6hdoZr7d2fbDaFbEW0Iz/9SZVSvr1s2SngRY0oMl/SXrZsMdK5IeV/pEvg1cK2m5pLH6gVWcRTMg58xy2b+0Da3skXRE0vOAD9AsnymaM5hfRbM64Mtt/2O14iqQtMz2gn5tkq6yvW+l0jolaWeatcmfRfPv4j+AE23/uGphFUj6OvAm218u958O/J3tJ9Wsq2v99kiHfS91HDuyqrD9+TJNymNpvjC+09PB/o/VCqvnJ5JOolklEZo+ozslzQB+Xa+sbpXlVP+0dh1DYvuJEAGwfYmk7afaYAu1VtKetr8HUPqK1lauaUoJko6UDrPXAbvZfrmkeZIeY/vfa9dWyZ/QTBnz2XL/v0vbDMZg7XZJp0zxsG3/bWfFDI/vS/pr4GPl/tE065ePmzcAX5b0fZofnbsx5KcM5NBWRySdTzON/LG295G0Lc2UIPvWrawuSTuMY6dqmZhvsu1phr0+zPbIzbfUVhmp9FbgKaXpq8Bbx2n23zLUdzeaExF3Yd3Ri3uqFrYBCZKO9Bz/z+gcoHQwfwjYwfZYnz9RRimdSBMiS4B32769blXdKcvI/l/gd4AVwEeGeYTSdCnzz/0dTT/qHsBC2xfUrWowGbXVnXvLXogBJO0JDPWvjGn2XpqFfH4MYPtbrBvuOBYk7STpbcDVNIeZ97d90jiFSLEYWEATIs8F3lW3nGpeC+xt+2DgSTSrQ46E9JF051SaIa+7SvoX4Mk0q6GNLds3T5r6Yag7FDcnSe8CXgicDTxuHA/v9ZjfMyP2h4ErKtdTy722VwPY/r6krWsXNKgESUdsXyzpSprp0kUzxPOOymXVdL/zJ2gmsxyn8ydeT7NH+mbgTT2BOrEGx6xahVXwm8NYtu8b9nmlptHcSUsN3+/+MJ/hnz6Saba+pVQnjNOSqr1y/kRMkLQWmJiwUqxbhnmsQlXSlLOB217cVS0bK0EyzSYtpTrBNPNu7WJ7RpXCIiI2kxzammZ9llLdHTiJ5pf439WoqaacPxGx5cmorY6UExDPoVnxbTlNB+MZdauq4ud9LtAMfT2pVlERselyaGuaSdoHeBOwN/D3NAvVjM3opKmM+/kTEf1I2sn2T2rXsTESJNOsdCTeTLOE6gMCZJhHYkyXshbJ62jmmFoMvG+czl6OmIqkG4CrgI8CF3kEvqTTRzL9Xla7gGGS8yciNmgvmj7UlwFnlOmVzrH93bplrV/2SKJTkn5Nc/7Efdx/6eGxGuoZMQhJzwA+TjMP27eAk21fWreqB0qQREQMEUkPo5n5+BjgNuDDwAXAvsC/2t6jXnX95dBWRMRwuZRmKv3Dba/qaV8m6QOVappS9kg6MoojMSKie5I0Ch3svRIkHRnFkRgR0R1JF3L/fsP7sf2CDsvZKAmSjqiZiW5iJMaBwNCPxIiI7kh62lSP2/5KV7VsrARJBaMyEiMi6ihrFz3K9vW1axlEpkjpiKSHSTpR0jLgL4HXADvTTCf+iarFRcTQkPR8msPgXyj395U01CslZtRWd0ZuJEZEVPEWmsPflwDYvqpM9jq0EiTdecz6Othtv7PrYiJiaN1n+6ejtMBXgmSa9Y7E6PcPY5hHYkREFd+W9CfADEnzaFYP/XrlmqaUzvZpNsojMSKie5K2o5kx/Nk0Uwd9Efhb23dXLWwKCZIOjdpIjIiIQWTUVkdGcSRGRHRP0gJJn5F0paSrJy6165pK9kg6Imk58EzgEtv7lbarbT++bmURMUwkXQ+8AVgB/Hqi3fYPqxW1Aels787IjcSIiCpW2x6poxUJku6M3EiMiKjiVEkfApbSrN0DgO3P1Ctpajm01ZFRHIkREd2T9HHgscA1rDu0ZdtDu9pqgiQiYohIWmH7cbXr2Bg5tNURSQuANwK70/O5p7M9Iia5TNJ829fWLmRQ2SPpyCiOxIiI7km6DtgTuJGmj0Q0h7aG9kdn9ki6M3IjMSKiikNrF7CxskfSEUmHAC9mhEZiREQdkp4CzLP9UUmzgR1s31i7rvXJHkl3XkozEmMrekZiAAmSiPgNSacCC4DH0CzNvRXNQnhPrlnXVBIk3XnCqI3EiIgq/hDYD7gSwPYtkh5St6SpZa6t7lwmaX7tIiJi6N1b1i6aWH5i+8r1bFD2SLrzFOA4SSMzEiMiqlgi6Z+Bh0p6OfAy4IOVa5pSOts7Imm3fu0Z/hsRE9RMxjeXpj/1N7Ng2L64amEbkCDp0KiNxIiI7klabvuA2nVsjPSRdKSMxDgJWFSaJkZiRET0ukzS79YuYmNkj6Qjkq6ijMTIeiQRsT6SrgX2An4I/JwR6E9NZ3t37rVtSSMzEiMiqnhu7QI2Vg5tdWfySIz/ZMhHYkREFW+z/cPeC/C22kVNJXskHSgjMc6nGYlxF80Zq6cM+0iMiKhi7947kmYAQ935niDpQDmk9dkyEiPhEREPIGkRzVIT20q6a6IZuJchP3qRzvaOSHo/cI7tb9SuJSKGl6S321604WcOj/SRdOcZwKWSvifpakkrJF1du6iIGDore+9ImlFOHxhaObTVnZEbiRERVRwi6Y+A44GdgY8AX6lb0tRyaKsjkj5m+5gNtUVESHoR8H7gF8CLbX+tcklTyqGt7ozcSIyI6J6kecCJwKeBHwDHSNqualEbkCCZZpIWSVoDPF7SXeWyBrgdyNK7ETHZhcBf234F8DTgBmCoB+nk0FZHRnEkRkR0T9Is23dNaptn+4ZaNW1I9ki6M3IjMSKiO5L+CsD2XZKOnPTwSyuUNLAESXcOkfR5SY+Q9DjgMmCol8+MiE4d1XN78tGLQ7ssZGNl+G9HbP9JGYmxghEZiRERndJ6bve7P1SyR9KRURyJERGd8npu97s/VNLZ3hFJ3wFOsL20TOL4OuBltvfewKYRMQYkrWXd+iPb0hy5oNzfxvZWtWrbkARJR0ZxJEZExCByaGuajfJIjIiIQSRIpt/IjsSIiBhEgmT6jexIjIiIQSRIpt/IjsSIiBhEOtun2SiPxIiIGESCJCIiWsmhrYiIaCVBEhERrSRIIiKilQRJxIAkvUnSNZKulnSVpCduwmvsK+l5PfdfIOnkzVvpA97z6ZKeNJ3vEeMts/9GDEDSwcAfAPvbvkfSzsCDN+Gl9gUWAJ8HsH0B079S5tOBnwFfn+b3iTGVUVsRA5D0QuCltp8/qf0A4D3ADsAdwEts3yrpEuBy4BnAQ4Hjy/2VNMPAfwS8vdxeYPvVks4Bfgk8FtiNZgqd44CDgcttv6S857OBtwJbA98rdf1M0g+AxcDzga2AI4G7ada+WQusBl5j+78264cTYy+HtiIG8x/ArpK+K+lMSU+TtBVwBnCE7QOAjwCn9Wwz0/aBwGuBU23fC5wCnG97X9vn93mfHYFnAn9Bs3b3e4G9gceVw2I7A28GnmV7f2AZzUzSE+4o7WcBf2n7B8AHgPeW90yIxGaXQ1sRAyi/+A8Ankqzl3E+8DZgH+DiZmUAZgC39mz2mXK9HNh9wLe60LYlrQBus70CQNI15TXmAvOBr5X3fDBw6Xre84WD/4URmy5BEjEg22uBS4BLyhf9CcA1tg9ezyb3lOu1DP5/bWKbX/fcnrg/s7zWxbZfvBnfM6KVHNqKGICkx5RVLifsC1wHzC4d8UjaStKGFipbAzykRSmXAU+W9DvlPbeTtNc0v2fElBIkEYPZAVgs6VpJV9McXjoFOAJ4p6RvAVcBGxpm+2Vgfhk+/KKNLcL2auAlwCdLHZfRdM5P5ULgD8t7PnVj3zNiQzJqKyIiWskeSUREtJIgiYiIVhIkERHRSoIkIiJaSZBEREQrCZKIiGglQRIREa0kSCIiopX/D5CdJ2W0e51UAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "order = ['Extremely Negative', 'Negative', 'Neutral','Positive','Extremely Positive']\n",
    "sns.countplot(x = 'Sentiment', data = tweet, order = order)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c4c23b",
   "metadata": {},
   "source": [
    "#### reference: https://www.analyticsvidhya.com/blog/2021/06/twitter-sentiment-analysis-a-nlp-use-case-for-beginners/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8aa28e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a4d75c87a5e3>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tweet['OriginalTweet'] = tweet['OriginalTweet'].str.lower()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UserName\n",
       "3799    @menyrbie @phil_gahan @chrisitv https://t.co/i...\n",
       "3800    advice talk to your neighbours family to excha...\n",
       "3801    coronavirus australia: woolworths to give elde...\n",
       "3802    my food stock is not the only one which is emp...\n",
       "3803    me, ready to go at supermarket during the #cov...\n",
       "3804    as news of the regions first confirmed covid-...\n",
       "3805    cashier at grocery store was sharing his insig...\n",
       "3806    was at the supermarket today. didn't buy toile...\n",
       "3807    due to covid-19 our retail store and classroom...\n",
       "3808    for corona prevention,we should stop to buy th...\n",
       "Name: OriginalTweet, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lower case all text\n",
    "tweet['OriginalTweet'] = tweet['OriginalTweet'].str.lower()\n",
    "#tweet['OriginalTweet'] = tweet_text \n",
    "tweet['OriginalTweet'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56651c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwordlist = ['a','ain', 'am', 'an',\n",
    "             'and','any','are', 'as', 'at', 'be',  'before',\n",
    "             'being', 'between', 'by', 'can', 'd', 'do',\n",
    "             'does', 'doing',  'during',  'for', 'from',\n",
    "             'had', 'has', 'have', 'having', 'he', 'her', 'here',\n",
    "             'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'in',\n",
    "             'into','is', 'it', 'its', 'itself', 'll', 'm', 'ma',\n",
    "             'me', 'my', 'myself', 'now', 'o', 'of', 'on', 'once',\n",
    "             'or',  'our', 'ours','ourselves',  'own', 're','s', 'she', \"shes\", \n",
    "             't', 'than', 'that', \"thatll\", 'the', 'their', 'theirs', 'them',\n",
    "             'themselves', 'then', 'there', 'these', 'they', 'this', 'those',\n",
    "             'through', 'to', 've', \n",
    "             'we',  'what', 'when', 'where','which','while', 'who', 'whom',\n",
    "             'why', 'will', 'with', 'y', 'you', \"youd\",\"youll\", \"youre\",\n",
    "             \"youve\", 'your', 'yours', 'yourself', 'yourselves']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05066cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-6c09ff49c4a4>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tweet['OriginalTweet'] = tweet['OriginalTweet'].apply(lambda text: cleaning_stopwords(text))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UserName\n",
       "3799    @menyrbie @phil_gahan @chrisitv https://t.co/i...\n",
       "3800    advice talk neighbours family exchange phone n...\n",
       "3801    coronavirus australia: woolworths give elderly...\n",
       "3802    food stock not only one empty... please, don't...\n",
       "3803    me, ready go supermarket #covid19 outbreak. no...\n",
       "Name: OriginalTweet, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STOPWORDS = set(stopwordlist)\n",
    "def cleaning_stopwords(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "tweet['OriginalTweet'] = tweet['OriginalTweet'].apply(lambda text: cleaning_stopwords(text))\n",
    "tweet['OriginalTweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e22efd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-2bef1d3d1219>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tweet['OriginalTweet'] = tweet['OriginalTweet'].apply(lambda text: remove_at_signs(text))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UserName\n",
       "3799    https://t.co/ifz9fan2pa https://t.co/xx6ghgfzc...\n",
       "3800    advice talk neighbours family exchange phone n...\n",
       "3801    coronavirus australia: woolworths give elderly...\n",
       "3802    food stock not only one empty... please, don't...\n",
       "3803    me, ready go supermarket #covid19 outbreak. no...\n",
       "Name: OriginalTweet, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_at_signs(text):\n",
    "    return \" \".join([word for word in str(text).split() if not word.startswith('@')])\n",
    "tweet['OriginalTweet'] = tweet['OriginalTweet'].apply(lambda text: remove_at_signs(text))\n",
    "tweet['OriginalTweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7287735",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-dbc6b0c6c066>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tweet['OriginalTweet'] = tweet['OriginalTweet'].apply(lambda x: cleaning_URLs(x))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UserName\n",
       "3799                                        url  url  url\n",
       "3800    advice talk neighbours family exchange phone n...\n",
       "3801    coronavirus australia: woolworths give elderly...\n",
       "3802    food stock not only one  url please, don't pan...\n",
       "3803    me, ready go supermarket #covid19 outbreak. no...\n",
       "Name: OriginalTweet, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleaning_URLs(data):\n",
    "    return re.sub('[^ ]+\\.[^ ]+' , ' url', data)\n",
    "tweet['OriginalTweet'] = tweet['OriginalTweet'].apply(lambda x: cleaning_URLs(x))\n",
    "tweet['OriginalTweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60f60b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' url  url  url'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet.loc[3799, 'OriginalTweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1461c682",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-c0b58da7c31c>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tweet['OriginalTweet']= tweet['OriginalTweet'].apply(lambda x: cleaning_punctuations(x))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UserName\n",
       "3799                                        url  url  url\n",
       "3800    advice talk neighbours family exchange phone n...\n",
       "3801    coronavirus australia woolworths give elderly ...\n",
       "3802    food stock not only one  url please dont panic...\n",
       "3803    me ready go supermarket covid19 outbreak not b...\n",
       "Name: OriginalTweet, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "english_punctuations = string.punctuation\n",
    "punctuations_list = english_punctuations\n",
    "def cleaning_punctuations(text):\n",
    "    translator = str.maketrans(' ', ' ', punctuations_list)\n",
    "    return text.translate(translator)\n",
    "tweet['OriginalTweet']= tweet['OriginalTweet'].apply(lambda x: cleaning_punctuations(x))\n",
    "tweet['OriginalTweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31789fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-260ba1a553fd>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tweet['OriginalTweet'] = tweet['OriginalTweet'].apply(lambda x: cleaning_repeating_char(x))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UserName\n",
       "3799                                          url url url\n",
       "3800    advice talk neighbours family exchange phone n...\n",
       "3801    coronavirus australia wolworths give elderly d...\n",
       "3802    fod stock not only one url please dont panic e...\n",
       "3803    me ready go supermarket covid19 outbreak not b...\n",
       "3804    news regions first confirmed covid19 case cam...\n",
       "3805    cashier grocery store was sharing insights cov...\n",
       "3806    was supermarket today didnt buy toilet paper r...\n",
       "3807    due covid19 retail store clasrom atlanta not o...\n",
       "3808    corona preventionwe should stop buy things cas...\n",
       "Name: OriginalTweet, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "def cleaning_repeating_char(text):\n",
    "    cl = ''.join(ch for ch, _ in itertools.groupby(text))\n",
    "    return cl\n",
    "tweet['OriginalTweet'] = tweet['OriginalTweet'].apply(lambda x: cleaning_repeating_char(x))\n",
    "tweet['OriginalTweet'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3fc8e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-39d2e1561b65>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tweet['OriginalTweet'] = tweet['OriginalTweet'].apply(lambda x: cleaning_numbers(x))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UserName\n",
       "3799                                          url url url\n",
       "3800    advice talk neighbours family exchange phone n...\n",
       "3801    coronavirus australia wolworths give elderly d...\n",
       "3802    fod stock not only one url please dont panic e...\n",
       "3803    me ready go supermarket covid outbreak not bec...\n",
       "3804    news regions first confirmed covid case came ...\n",
       "3805    cashier grocery store was sharing insights cov...\n",
       "3806    was supermarket today didnt buy toilet paper r...\n",
       "3807    due covid retail store clasrom atlanta not ope...\n",
       "3808    corona preventionwe should stop buy things cas...\n",
       "Name: OriginalTweet, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleaning_numbers(data):\n",
    "    return re.sub('[0-9]+', '', data)\n",
    "tweet['OriginalTweet'] = tweet['OriginalTweet'].apply(lambda x: cleaning_numbers(x))\n",
    "tweet['OriginalTweet'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbcef28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove non_English words\n",
    "# import nltk\n",
    "# nltk.download('words')\n",
    "# words = set(nltk.corpus.words.words())\n",
    "# def remove_non_english(text):\n",
    "#     eng = \" \".join(w for w in nltk.wordpunct_tokenize(text) \\\n",
    "#          if w.lower() in words or not w.isalpha())\n",
    "#     return eng\n",
    "\n",
    "# tweet['OriginalTweet'] = tweet['OriginalTweet'].apply(lambda x: remove_non_english(x))\n",
    "# tweet['OriginalTweet'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "258cb3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the first original tweet to learn how tweet tokenizer works\n",
    "# Try_tweet1 = tweet.iloc[0, 3]\n",
    "# print(Try_tweet1)\n",
    "# print(tweet.iloc[0, 4])\n",
    "# Try_token = nltk.tokenize.TweetTokenizer().tokenize(Try_tweet1)\n",
    "# print(Try_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2efe2d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-116119311db9>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tweet['Tokens'] = [tknzr.tokenize(t) for t in tweet['OriginalTweet']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UserName\n",
       "3799                                      [url, url, url]\n",
       "3800    [advice, talk, neighbours, family, exchange, p...\n",
       "3801    [coronavirus, australia, wolworths, give, elde...\n",
       "3802    [fod, stock, not, only, one, url, please, dont...\n",
       "3803    [me, ready, go, supermarket, covid, outbreak, ...\n",
       "Name: Tokens, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize the OriginalTweet text\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer()\n",
    "tweet['Tokens'] = [tknzr.tokenize(t) for t in tweet['OriginalTweet']]\n",
    "tweet['Tokens'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c0e38c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-9e413b8e77ce>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tweet['Tokens']= tweet['Tokens'].apply(lambda x: stemming_on_text(x))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UserName\n",
       "3799                                      [url, url, url]\n",
       "3800    [advice, talk, neighbours, family, exchange, p...\n",
       "3801    [coronavirus, australia, wolworths, give, elde...\n",
       "3802    [fod, stock, not, only, one, url, please, dont...\n",
       "3803    [me, ready, go, supermarket, covid, outbreak, ...\n",
       "3804    [news, region, , s, first, confirmed, covid, ...\n",
       "3805    [cashier, grocery, store, was, sharing, insigh...\n",
       "3806    [was, supermarket, today, didnt, buy, toilet, ...\n",
       "3807    [due, covid, retail, store, clasrom, atlanta, ...\n",
       "3808    [corona, preventionwe, should, stop, buy, thin...\n",
       "Name: Tokens, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = nltk.PorterStemmer()\n",
    "def stemming_on_text(data):\n",
    "    text = [st.stem(word) for word in data]\n",
    "    return data\n",
    "tweet['Tokens']= tweet['Tokens'].apply(lambda x: stemming_on_text(x))\n",
    "tweet['Tokens'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9735cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-da252269bd34>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tweet['Tokens'] = tweet['Tokens'].apply(lambda x: lemmatizer_on_text(x))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UserName\n",
       "3799                                      [url, url, url]\n",
       "3800    [advice, talk, neighbours, family, exchange, p...\n",
       "3801    [coronavirus, australia, wolworths, give, elde...\n",
       "3802    [fod, stock, not, only, one, url, please, dont...\n",
       "3803    [me, ready, go, supermarket, covid, outbreak, ...\n",
       "3804    [news, region, , s, first, confirmed, covid, ...\n",
       "3805    [cashier, grocery, store, was, sharing, insigh...\n",
       "3806    [was, supermarket, today, didnt, buy, toilet, ...\n",
       "3807    [due, covid, retail, store, clasrom, atlanta, ...\n",
       "3808    [corona, preventionwe, should, stop, buy, thin...\n",
       "Name: Tokens, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = nltk.stem.WordNetLemmatizer()\n",
    "def lemmatizer_on_text(data):\n",
    "    text = [lm.lemmatize(word) for word in data]\n",
    "    return data\n",
    "tweet['Tokens'] = tweet['Tokens'].apply(lambda x: lemmatizer_on_text(x))\n",
    "tweet['Tokens'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7006bf1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UserName\n",
      "3799                                          url url url\n",
      "3800    advice talk neighbours family exchange phone n...\n",
      "3801    coronavirus australia wolworths give elderly d...\n",
      "3802    fod stock not only one url please dont panic e...\n",
      "3803    me ready go supermarket covid outbreak not bec...\n",
      "3804    news region  s first confirmed covid case cam...\n",
      "3805    cashier grocery store was sharing insights cov...\n",
      "3806    was supermarket today didnt buy toilet paper r...\n",
      "3807    due covid retail store clasrom atlanta not ope...\n",
      "3808    corona preventionwe should stop buy things cas...\n",
      "Name: text, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-cc0ea48d3dc6>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tweet['text'] = tweet[\"Tokens\"].map(' '.join)\n"
     ]
    }
   ],
   "source": [
    "tweet['text'] = tweet[\"Tokens\"].map(' '.join)\n",
    "print(tweet['text'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6312eb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer  \n",
    "# from sklearn.model_selection import train_test_split \n",
    "\n",
    "# X = tweet['text'] \n",
    "\n",
    "# y = tweet['Sentiment']\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 1)\n",
    "\n",
    "# Count_vect = CountVectorizer()\n",
    "# Count_train = Count_vect.fit_transform(X_train)\n",
    "\n",
    "# Count_test = Count_vect.transform(X_test)\n",
    "\n",
    "# print(Count_vect.get_feature_names()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd38fc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MultiLabelBinarizer\n",
    "# from sklearn.model_selection import train_test_split \n",
    "\n",
    "# X = tweet['Tokens']\n",
    "# y = tweet['Sentiment']\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 1)\n",
    "\n",
    "# # Vectorize the X\n",
    "# MLB_vect = MultiLabelBinarizer()\n",
    "\n",
    "# MLB_X_train = MLB_vect.fit_transform(X_train)\n",
    "\n",
    "# MLB_X_test = MLB_vect.transform(X_test)\n",
    "\n",
    "# len(MLB_vect.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e847e0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of feature names 5535\n",
      "['abc', 'ability', 'able', 'about', 'above', 'absolute', 'absolutely', 'absurd', 'abt', 'abuse']\n",
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "X = tweet['text'] \n",
    "\n",
    "y = tweet['Sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 1)\n",
    "\n",
    "# Initialize a TfidfVectorizer object: tfidf_vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df = 10, max_df = 0.7)\n",
    "\n",
    "# Transform the training data: tfidf_train \n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data: tfidf_test \n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Print the first 10 features\n",
    "print('# of feature names', len(tfidf_vectorizer.get_feature_names()))\n",
    "print(tfidf_vectorizer.get_feature_names()[:10])\n",
    "\n",
    "# Print the first 5 vectors of the tfidf training data\n",
    "print(tfidf_train.A[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d6527c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 µs, sys: 1e+03 ns, total: 7 µs\n",
      "Wall time: 11.9 µs\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Extremely Negative       0.60      0.61      0.61      1342\n",
      "Extremely Positive       0.65      0.63      0.64      1674\n",
      "          Negative       0.50      0.47      0.48      2466\n",
      "           Neutral       0.60      0.70      0.65      1939\n",
      "          Positive       0.52      0.50      0.51      2869\n",
      "\n",
      "          accuracy                           0.56     10290\n",
      "         macro avg       0.57      0.58      0.58     10290\n",
      "      weighted avg       0.56      0.56      0.56     10290\n",
      "\n",
      "0.5648202137998056\n",
      "[[ 823    9  391   52   67]\n",
      " [   9 1047   64   62  492]\n",
      " [ 422   69 1155  361  459]\n",
      " [  28   28  227 1349  307]\n",
      " [  85  465  469  412 1438]]\n"
     ]
    }
   ],
   "source": [
    "## get running time\n",
    "%time\n",
    "\n",
    "## Try NaiveBayes first\n",
    "# Import the necessary modules\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# # using tfidf ## F1 0.44 fast to run\n",
    "# NB_classifier = MultinomialNB()\n",
    "# # Fit the classifier to the training data\n",
    "# NB_classifier.fit(tfidf_train, y_train)\n",
    "# # Create the predicted tags: pred\n",
    "# pred = NB_classifier.predict(tfidf_test)\n",
    "# # Calculate the accuracy score: score\n",
    "# Score = metrics.accuracy_score(y_test, pred)\n",
    "# print(Score)\n",
    "# # Calculate the confusion matrix: cm\n",
    "# CM = metrics.confusion_matrix(y_test, pred)\n",
    "# print(CM)\n",
    "\n",
    "\n",
    "# # Using Count_train\n",
    "# nb_classifier = MultinomialNB()\n",
    "# # Fit the classifier to the training data\n",
    "# nb_classifier.fit(Count_train, y_train)\n",
    "# # Create the predicted tags: pred\n",
    "# pred = nb_classifier.predict(Count_test)\n",
    "# # Calculate the accuracy score: score\n",
    "# score = metrics.accuracy_score(y_test, pred)\n",
    "# print(Score)\n",
    "# # Calculate the confusion matrix: cm\n",
    "# cm = metrics.confusion_matrix(y_test, pred)\n",
    "# print(CM)\n",
    "\n",
    "# # F1 = 0.49 fast to run\n",
    "# BNBmodel = BernoulliNB()\n",
    "# BNBmodel.fit(tfidf_train, y_train)\n",
    "# y_pred = BNBmodel.predict(tfidf_test)\n",
    "# print(classification_report(y_test, y_pred))\n",
    "# print(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "## F1 LinearSVC = 0.56\n",
    "SVCmodel = LinearSVC()\n",
    "SVCmodel.fit(tfidf_train, y_train)\n",
    "y_pred = SVCmodel.predict(tfidf_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "CM = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(CM)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "717e3cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
      "Wall time: 6.91 µs\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "[CV 1/5; 1/32] START C=0.1, degree=0, gamma=1, kernel=rbf.......................\n",
      "[CV 1/5; 1/32] END .....C=0.1, degree=0, gamma=1, kernel=rbf; total time= 4.5min\n",
      "[CV 2/5; 1/32] START C=0.1, degree=0, gamma=1, kernel=rbf.......................\n",
      "[CV 2/5; 1/32] END .....C=0.1, degree=0, gamma=1, kernel=rbf; total time= 4.6min\n",
      "[CV 3/5; 1/32] START C=0.1, degree=0, gamma=1, kernel=rbf.......................\n",
      "[CV 3/5; 1/32] END .....C=0.1, degree=0, gamma=1, kernel=rbf; total time= 4.6min\n",
      "[CV 4/5; 1/32] START C=0.1, degree=0, gamma=1, kernel=rbf.......................\n",
      "[CV 4/5; 1/32] END .....C=0.1, degree=0, gamma=1, kernel=rbf; total time= 4.8min\n",
      "[CV 5/5; 1/32] START C=0.1, degree=0, gamma=1, kernel=rbf.......................\n",
      "[CV 5/5; 1/32] END .....C=0.1, degree=0, gamma=1, kernel=rbf; total time= 4.7min\n",
      "[CV 1/5; 2/32] START C=0.1, degree=0, gamma=1, kernel=poly......................\n",
      "[CV 1/5; 2/32] END ....C=0.1, degree=0, gamma=1, kernel=poly; total time= 3.7min\n",
      "[CV 2/5; 2/32] START C=0.1, degree=0, gamma=1, kernel=poly......................\n",
      "[CV 2/5; 2/32] END ....C=0.1, degree=0, gamma=1, kernel=poly; total time= 3.6min\n",
      "[CV 3/5; 2/32] START C=0.1, degree=0, gamma=1, kernel=poly......................\n",
      "[CV 3/5; 2/32] END ....C=0.1, degree=0, gamma=1, kernel=poly; total time= 3.6min\n",
      "[CV 4/5; 2/32] START C=0.1, degree=0, gamma=1, kernel=poly......................\n",
      "[CV 4/5; 2/32] END ....C=0.1, degree=0, gamma=1, kernel=poly; total time= 3.6min\n",
      "[CV 5/5; 2/32] START C=0.1, degree=0, gamma=1, kernel=poly......................\n",
      "[CV 5/5; 2/32] END ....C=0.1, degree=0, gamma=1, kernel=poly; total time= 3.6min\n",
      "[CV 1/5; 3/32] START C=0.1, degree=0, gamma=1, kernel=sigmoid...................\n",
      "[CV 1/5; 3/32] END .C=0.1, degree=0, gamma=1, kernel=sigmoid; total time= 3.8min\n",
      "[CV 2/5; 3/32] START C=0.1, degree=0, gamma=1, kernel=sigmoid...................\n",
      "[CV 2/5; 3/32] END .C=0.1, degree=0, gamma=1, kernel=sigmoid; total time= 3.9min\n",
      "[CV 3/5; 3/32] START C=0.1, degree=0, gamma=1, kernel=sigmoid...................\n",
      "[CV 3/5; 3/32] END .C=0.1, degree=0, gamma=1, kernel=sigmoid; total time= 3.9min\n",
      "[CV 4/5; 3/32] START C=0.1, degree=0, gamma=1, kernel=sigmoid...................\n",
      "[CV 4/5; 3/32] END .C=0.1, degree=0, gamma=1, kernel=sigmoid; total time= 3.9min\n",
      "[CV 5/5; 3/32] START C=0.1, degree=0, gamma=1, kernel=sigmoid...................\n",
      "[CV 5/5; 3/32] END .C=0.1, degree=0, gamma=1, kernel=sigmoid; total time= 3.9min\n",
      "[CV 1/5; 4/32] START C=0.1, degree=0, gamma=1, kernel=linear....................\n",
      "[CV 1/5; 4/32] END ..C=0.1, degree=0, gamma=1, kernel=linear; total time= 4.0min\n",
      "[CV 2/5; 4/32] START C=0.1, degree=0, gamma=1, kernel=linear....................\n",
      "[CV 2/5; 4/32] END ..C=0.1, degree=0, gamma=1, kernel=linear; total time= 4.1min\n",
      "[CV 3/5; 4/32] START C=0.1, degree=0, gamma=1, kernel=linear....................\n",
      "[CV 3/5; 4/32] END ..C=0.1, degree=0, gamma=1, kernel=linear; total time= 4.0min\n",
      "[CV 4/5; 4/32] START C=0.1, degree=0, gamma=1, kernel=linear....................\n",
      "[CV 4/5; 4/32] END ..C=0.1, degree=0, gamma=1, kernel=linear; total time= 4.0min\n",
      "[CV 5/5; 4/32] START C=0.1, degree=0, gamma=1, kernel=linear....................\n",
      "[CV 5/5; 4/32] END ..C=0.1, degree=0, gamma=1, kernel=linear; total time= 4.0min\n",
      "[CV 1/5; 5/32] START C=0.1, degree=0, gamma=0.001, kernel=rbf...................\n",
      "[CV 1/5; 5/32] END .C=0.1, degree=0, gamma=0.001, kernel=rbf; total time= 4.3min\n",
      "[CV 2/5; 5/32] START C=0.1, degree=0, gamma=0.001, kernel=rbf...................\n",
      "[CV 2/5; 5/32] END .C=0.1, degree=0, gamma=0.001, kernel=rbf; total time= 4.3min\n",
      "[CV 3/5; 5/32] START C=0.1, degree=0, gamma=0.001, kernel=rbf...................\n",
      "[CV 3/5; 5/32] END .C=0.1, degree=0, gamma=0.001, kernel=rbf; total time= 4.3min\n",
      "[CV 4/5; 5/32] START C=0.1, degree=0, gamma=0.001, kernel=rbf...................\n",
      "[CV 4/5; 5/32] END .C=0.1, degree=0, gamma=0.001, kernel=rbf; total time= 4.4min\n",
      "[CV 5/5; 5/32] START C=0.1, degree=0, gamma=0.001, kernel=rbf...................\n",
      "[CV 5/5; 5/32] END .C=0.1, degree=0, gamma=0.001, kernel=rbf; total time= 4.3min\n",
      "[CV 1/5; 6/32] START C=0.1, degree=0, gamma=0.001, kernel=poly..................\n",
      "[CV 1/5; 6/32] END C=0.1, degree=0, gamma=0.001, kernel=poly; total time= 3.5min\n",
      "[CV 2/5; 6/32] START C=0.1, degree=0, gamma=0.001, kernel=poly..................\n",
      "[CV 2/5; 6/32] END C=0.1, degree=0, gamma=0.001, kernel=poly; total time= 3.5min\n",
      "[CV 3/5; 6/32] START C=0.1, degree=0, gamma=0.001, kernel=poly..................\n",
      "[CV 3/5; 6/32] END C=0.1, degree=0, gamma=0.001, kernel=poly; total time= 3.5min\n",
      "[CV 4/5; 6/32] START C=0.1, degree=0, gamma=0.001, kernel=poly..................\n",
      "[CV 4/5; 6/32] END C=0.1, degree=0, gamma=0.001, kernel=poly; total time= 3.6min\n",
      "[CV 5/5; 6/32] START C=0.1, degree=0, gamma=0.001, kernel=poly..................\n",
      "[CV 5/5; 6/32] END C=0.1, degree=0, gamma=0.001, kernel=poly; total time= 3.5min\n",
      "[CV 1/5; 7/32] START C=0.1, degree=0, gamma=0.001, kernel=sigmoid...............\n",
      "[CV 1/5; 7/32] END C=0.1, degree=0, gamma=0.001, kernel=sigmoid; total time= 3.8min\n",
      "[CV 2/5; 7/32] START C=0.1, degree=0, gamma=0.001, kernel=sigmoid...............\n",
      "[CV 2/5; 7/32] END C=0.1, degree=0, gamma=0.001, kernel=sigmoid; total time= 3.9min\n",
      "[CV 3/5; 7/32] START C=0.1, degree=0, gamma=0.001, kernel=sigmoid...............\n",
      "[CV 3/5; 7/32] END C=0.1, degree=0, gamma=0.001, kernel=sigmoid; total time= 3.8min\n",
      "[CV 4/5; 7/32] START C=0.1, degree=0, gamma=0.001, kernel=sigmoid...............\n",
      "[CV 4/5; 7/32] END C=0.1, degree=0, gamma=0.001, kernel=sigmoid; total time= 3.8min\n",
      "[CV 5/5; 7/32] START C=0.1, degree=0, gamma=0.001, kernel=sigmoid...............\n",
      "[CV 5/5; 7/32] END C=0.1, degree=0, gamma=0.001, kernel=sigmoid; total time= 3.9min\n",
      "[CV 1/5; 8/32] START C=0.1, degree=0, gamma=0.001, kernel=linear................\n",
      "[CV 1/5; 8/32] END C=0.1, degree=0, gamma=0.001, kernel=linear; total time= 4.1min\n",
      "[CV 2/5; 8/32] START C=0.1, degree=0, gamma=0.001, kernel=linear................\n",
      "[CV 2/5; 8/32] END C=0.1, degree=0, gamma=0.001, kernel=linear; total time= 4.1min\n",
      "[CV 3/5; 8/32] START C=0.1, degree=0, gamma=0.001, kernel=linear................\n",
      "[CV 3/5; 8/32] END C=0.1, degree=0, gamma=0.001, kernel=linear; total time= 4.0min\n",
      "[CV 4/5; 8/32] START C=0.1, degree=0, gamma=0.001, kernel=linear................\n",
      "[CV 4/5; 8/32] END C=0.1, degree=0, gamma=0.001, kernel=linear; total time= 4.0min\n",
      "[CV 5/5; 8/32] START C=0.1, degree=0, gamma=0.001, kernel=linear................\n",
      "[CV 5/5; 8/32] END C=0.1, degree=0, gamma=0.001, kernel=linear; total time= 4.0min\n",
      "[CV 1/5; 9/32] START C=0.1, degree=3, gamma=1, kernel=rbf.......................\n",
      "[CV 1/5; 9/32] END .....C=0.1, degree=3, gamma=1, kernel=rbf; total time= 4.5min\n",
      "[CV 2/5; 9/32] START C=0.1, degree=3, gamma=1, kernel=rbf.......................\n",
      "[CV 2/5; 9/32] END .....C=0.1, degree=3, gamma=1, kernel=rbf; total time= 4.5min\n",
      "[CV 3/5; 9/32] START C=0.1, degree=3, gamma=1, kernel=rbf.......................\n",
      "[CV 3/5; 9/32] END .....C=0.1, degree=3, gamma=1, kernel=rbf; total time= 4.5min\n",
      "[CV 4/5; 9/32] START C=0.1, degree=3, gamma=1, kernel=rbf.......................\n",
      "[CV 4/5; 9/32] END .....C=0.1, degree=3, gamma=1, kernel=rbf; total time= 4.5min\n",
      "[CV 5/5; 9/32] START C=0.1, degree=3, gamma=1, kernel=rbf.......................\n",
      "[CV 5/5; 9/32] END .....C=0.1, degree=3, gamma=1, kernel=rbf; total time= 4.5min\n",
      "[CV 1/5; 10/32] START C=0.1, degree=3, gamma=1, kernel=poly.....................\n",
      "[CV 1/5; 10/32] END ...C=0.1, degree=3, gamma=1, kernel=poly; total time= 7.5min\n",
      "[CV 2/5; 10/32] START C=0.1, degree=3, gamma=1, kernel=poly.....................\n",
      "[CV 2/5; 10/32] END ...C=0.1, degree=3, gamma=1, kernel=poly; total time= 7.5min\n",
      "[CV 3/5; 10/32] START C=0.1, degree=3, gamma=1, kernel=poly.....................\n",
      "[CV 3/5; 10/32] END ...C=0.1, degree=3, gamma=1, kernel=poly; total time= 7.5min\n",
      "[CV 4/5; 10/32] START C=0.1, degree=3, gamma=1, kernel=poly.....................\n",
      "[CV 4/5; 10/32] END ...C=0.1, degree=3, gamma=1, kernel=poly; total time= 7.5min\n",
      "[CV 5/5; 10/32] START C=0.1, degree=3, gamma=1, kernel=poly.....................\n",
      "[CV 5/5; 10/32] END ...C=0.1, degree=3, gamma=1, kernel=poly; total time= 7.5min\n",
      "[CV 1/5; 11/32] START C=0.1, degree=3, gamma=1, kernel=sigmoid..................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 11/32] END C=0.1, degree=3, gamma=1, kernel=sigmoid; total time= 3.9min\n",
      "[CV 2/5; 11/32] START C=0.1, degree=3, gamma=1, kernel=sigmoid..................\n",
      "[CV 2/5; 11/32] END C=0.1, degree=3, gamma=1, kernel=sigmoid; total time= 3.9min\n",
      "[CV 3/5; 11/32] START C=0.1, degree=3, gamma=1, kernel=sigmoid..................\n",
      "[CV 3/5; 11/32] END C=0.1, degree=3, gamma=1, kernel=sigmoid; total time= 3.8min\n",
      "[CV 4/5; 11/32] START C=0.1, degree=3, gamma=1, kernel=sigmoid..................\n",
      "[CV 4/5; 11/32] END C=0.1, degree=3, gamma=1, kernel=sigmoid; total time= 3.8min\n",
      "[CV 5/5; 11/32] START C=0.1, degree=3, gamma=1, kernel=sigmoid..................\n",
      "[CV 5/5; 11/32] END C=0.1, degree=3, gamma=1, kernel=sigmoid; total time= 3.8min\n",
      "[CV 1/5; 12/32] START C=0.1, degree=3, gamma=1, kernel=linear...................\n",
      "[CV 1/5; 12/32] END .C=0.1, degree=3, gamma=1, kernel=linear; total time= 4.1min\n",
      "[CV 2/5; 12/32] START C=0.1, degree=3, gamma=1, kernel=linear...................\n",
      "[CV 2/5; 12/32] END .C=0.1, degree=3, gamma=1, kernel=linear; total time= 4.1min\n",
      "[CV 3/5; 12/32] START C=0.1, degree=3, gamma=1, kernel=linear...................\n",
      "[CV 3/5; 12/32] END .C=0.1, degree=3, gamma=1, kernel=linear; total time= 4.1min\n",
      "[CV 4/5; 12/32] START C=0.1, degree=3, gamma=1, kernel=linear...................\n",
      "[CV 4/5; 12/32] END .C=0.1, degree=3, gamma=1, kernel=linear; total time= 4.0min\n",
      "[CV 5/5; 12/32] START C=0.1, degree=3, gamma=1, kernel=linear...................\n",
      "[CV 5/5; 12/32] END .C=0.1, degree=3, gamma=1, kernel=linear; total time= 4.0min\n",
      "[CV 1/5; 13/32] START C=0.1, degree=3, gamma=0.001, kernel=rbf..................\n",
      "[CV 1/5; 13/32] END C=0.1, degree=3, gamma=0.001, kernel=rbf; total time= 4.3min\n",
      "[CV 2/5; 13/32] START C=0.1, degree=3, gamma=0.001, kernel=rbf..................\n",
      "[CV 2/5; 13/32] END C=0.1, degree=3, gamma=0.001, kernel=rbf; total time= 4.3min\n",
      "[CV 3/5; 13/32] START C=0.1, degree=3, gamma=0.001, kernel=rbf..................\n",
      "[CV 3/5; 13/32] END C=0.1, degree=3, gamma=0.001, kernel=rbf; total time= 4.3min\n",
      "[CV 4/5; 13/32] START C=0.1, degree=3, gamma=0.001, kernel=rbf..................\n",
      "[CV 4/5; 13/32] END C=0.1, degree=3, gamma=0.001, kernel=rbf; total time= 4.3min\n",
      "[CV 5/5; 13/32] START C=0.1, degree=3, gamma=0.001, kernel=rbf..................\n",
      "[CV 5/5; 13/32] END C=0.1, degree=3, gamma=0.001, kernel=rbf; total time= 4.3min\n",
      "[CV 1/5; 14/32] START C=0.1, degree=3, gamma=0.001, kernel=poly.................\n",
      "[CV 1/5; 14/32] END C=0.1, degree=3, gamma=0.001, kernel=poly; total time= 3.9min\n",
      "[CV 2/5; 14/32] START C=0.1, degree=3, gamma=0.001, kernel=poly.................\n",
      "[CV 2/5; 14/32] END C=0.1, degree=3, gamma=0.001, kernel=poly; total time= 4.6min\n",
      "[CV 3/5; 14/32] START C=0.1, degree=3, gamma=0.001, kernel=poly.................\n",
      "[CV 3/5; 14/32] END C=0.1, degree=3, gamma=0.001, kernel=poly; total time= 4.6min\n",
      "[CV 4/5; 14/32] START C=0.1, degree=3, gamma=0.001, kernel=poly.................\n",
      "[CV 4/5; 14/32] END C=0.1, degree=3, gamma=0.001, kernel=poly; total time= 4.6min\n",
      "[CV 5/5; 14/32] START C=0.1, degree=3, gamma=0.001, kernel=poly.................\n",
      "[CV 5/5; 14/32] END C=0.1, degree=3, gamma=0.001, kernel=poly; total time= 4.1min\n",
      "[CV 1/5; 15/32] START C=0.1, degree=3, gamma=0.001, kernel=sigmoid..............\n",
      "[CV 1/5; 15/32] END C=0.1, degree=3, gamma=0.001, kernel=sigmoid; total time= 4.2min\n",
      "[CV 2/5; 15/32] START C=0.1, degree=3, gamma=0.001, kernel=sigmoid..............\n",
      "[CV 2/5; 15/32] END C=0.1, degree=3, gamma=0.001, kernel=sigmoid; total time= 4.2min\n",
      "[CV 3/5; 15/32] START C=0.1, degree=3, gamma=0.001, kernel=sigmoid..............\n",
      "[CV 3/5; 15/32] END C=0.1, degree=3, gamma=0.001, kernel=sigmoid; total time= 4.2min\n",
      "[CV 4/5; 15/32] START C=0.1, degree=3, gamma=0.001, kernel=sigmoid..............\n",
      "[CV 4/5; 15/32] END C=0.1, degree=3, gamma=0.001, kernel=sigmoid; total time= 4.2min\n",
      "[CV 5/5; 15/32] START C=0.1, degree=3, gamma=0.001, kernel=sigmoid..............\n",
      "[CV 5/5; 15/32] END C=0.1, degree=3, gamma=0.001, kernel=sigmoid; total time= 4.2min\n",
      "[CV 1/5; 16/32] START C=0.1, degree=3, gamma=0.001, kernel=linear...............\n",
      "[CV 1/5; 16/32] END C=0.1, degree=3, gamma=0.001, kernel=linear; total time= 4.7min\n",
      "[CV 2/5; 16/32] START C=0.1, degree=3, gamma=0.001, kernel=linear...............\n",
      "[CV 2/5; 16/32] END C=0.1, degree=3, gamma=0.001, kernel=linear; total time= 4.7min\n",
      "[CV 3/5; 16/32] START C=0.1, degree=3, gamma=0.001, kernel=linear...............\n",
      "[CV 3/5; 16/32] END C=0.1, degree=3, gamma=0.001, kernel=linear; total time= 4.7min\n",
      "[CV 4/5; 16/32] START C=0.1, degree=3, gamma=0.001, kernel=linear...............\n",
      "[CV 4/5; 16/32] END C=0.1, degree=3, gamma=0.001, kernel=linear; total time= 4.6min\n",
      "[CV 5/5; 16/32] START C=0.1, degree=3, gamma=0.001, kernel=linear...............\n",
      "[CV 5/5; 16/32] END C=0.1, degree=3, gamma=0.001, kernel=linear; total time= 4.5min\n",
      "[CV 1/5; 17/32] START C=100, degree=0, gamma=1, kernel=rbf......................\n",
      "[CV 1/5; 17/32] END ....C=100, degree=0, gamma=1, kernel=rbf; total time=12.0min\n",
      "[CV 2/5; 17/32] START C=100, degree=0, gamma=1, kernel=rbf......................\n",
      "[CV 2/5; 17/32] END ....C=100, degree=0, gamma=1, kernel=rbf; total time=11.6min\n",
      "[CV 3/5; 17/32] START C=100, degree=0, gamma=1, kernel=rbf......................\n",
      "[CV 3/5; 17/32] END ....C=100, degree=0, gamma=1, kernel=rbf; total time=12.4min\n",
      "[CV 4/5; 17/32] START C=100, degree=0, gamma=1, kernel=rbf......................\n",
      "[CV 4/5; 17/32] END ....C=100, degree=0, gamma=1, kernel=rbf; total time=12.9min\n",
      "[CV 5/5; 17/32] START C=100, degree=0, gamma=1, kernel=rbf......................\n",
      "[CV 5/5; 17/32] END ....C=100, degree=0, gamma=1, kernel=rbf; total time=12.2min\n",
      "[CV 1/5; 18/32] START C=100, degree=0, gamma=1, kernel=poly.....................\n",
      "[CV 1/5; 18/32] END ...C=100, degree=0, gamma=1, kernel=poly; total time= 3.8min\n",
      "[CV 2/5; 18/32] START C=100, degree=0, gamma=1, kernel=poly.....................\n",
      "[CV 2/5; 18/32] END ...C=100, degree=0, gamma=1, kernel=poly; total time= 3.8min\n",
      "[CV 3/5; 18/32] START C=100, degree=0, gamma=1, kernel=poly.....................\n",
      "[CV 3/5; 18/32] END ...C=100, degree=0, gamma=1, kernel=poly; total time= 3.6min\n",
      "[CV 4/5; 18/32] START C=100, degree=0, gamma=1, kernel=poly.....................\n",
      "[CV 4/5; 18/32] END ...C=100, degree=0, gamma=1, kernel=poly; total time= 3.7min\n",
      "[CV 5/5; 18/32] START C=100, degree=0, gamma=1, kernel=poly.....................\n",
      "[CV 5/5; 18/32] END ...C=100, degree=0, gamma=1, kernel=poly; total time= 3.9min\n",
      "[CV 1/5; 19/32] START C=100, degree=0, gamma=1, kernel=sigmoid..................\n",
      "[CV 1/5; 19/32] END C=100, degree=0, gamma=1, kernel=sigmoid; total time=14.5min\n",
      "[CV 2/5; 19/32] START C=100, degree=0, gamma=1, kernel=sigmoid..................\n",
      "[CV 2/5; 19/32] END C=100, degree=0, gamma=1, kernel=sigmoid; total time=13.3min\n",
      "[CV 3/5; 19/32] START C=100, degree=0, gamma=1, kernel=sigmoid..................\n",
      "[CV 3/5; 19/32] END C=100, degree=0, gamma=1, kernel=sigmoid; total time=12.9min\n",
      "[CV 4/5; 19/32] START C=100, degree=0, gamma=1, kernel=sigmoid..................\n",
      "[CV 4/5; 19/32] END C=100, degree=0, gamma=1, kernel=sigmoid; total time=10.8min\n",
      "[CV 5/5; 19/32] START C=100, degree=0, gamma=1, kernel=sigmoid..................\n",
      "[CV 5/5; 19/32] END C=100, degree=0, gamma=1, kernel=sigmoid; total time=12.0min\n",
      "[CV 1/5; 20/32] START C=100, degree=0, gamma=1, kernel=linear...................\n",
      "[CV 1/5; 20/32] END .C=100, degree=0, gamma=1, kernel=linear; total time= 5.8min\n",
      "[CV 2/5; 20/32] START C=100, degree=0, gamma=1, kernel=linear...................\n",
      "[CV 2/5; 20/32] END .C=100, degree=0, gamma=1, kernel=linear; total time= 6.1min\n",
      "[CV 3/5; 20/32] START C=100, degree=0, gamma=1, kernel=linear...................\n",
      "[CV 3/5; 20/32] END .C=100, degree=0, gamma=1, kernel=linear; total time= 6.0min\n",
      "[CV 4/5; 20/32] START C=100, degree=0, gamma=1, kernel=linear...................\n",
      "[CV 4/5; 20/32] END .C=100, degree=0, gamma=1, kernel=linear; total time= 6.2min\n",
      "[CV 5/5; 20/32] START C=100, degree=0, gamma=1, kernel=linear...................\n",
      "[CV 5/5; 20/32] END .C=100, degree=0, gamma=1, kernel=linear; total time= 6.0min\n",
      "[CV 1/5; 21/32] START C=100, degree=0, gamma=0.001, kernel=rbf..................\n",
      "[CV 1/5; 21/32] END C=100, degree=0, gamma=0.001, kernel=rbf; total time= 4.1min\n",
      "[CV 2/5; 21/32] START C=100, degree=0, gamma=0.001, kernel=rbf..................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 21/32] END C=100, degree=0, gamma=0.001, kernel=rbf; total time= 4.1min\n",
      "[CV 3/5; 21/32] START C=100, degree=0, gamma=0.001, kernel=rbf..................\n",
      "[CV 3/5; 21/32] END C=100, degree=0, gamma=0.001, kernel=rbf; total time= 4.0min\n",
      "[CV 4/5; 21/32] START C=100, degree=0, gamma=0.001, kernel=rbf..................\n",
      "[CV 4/5; 21/32] END C=100, degree=0, gamma=0.001, kernel=rbf; total time= 4.0min\n",
      "[CV 5/5; 21/32] START C=100, degree=0, gamma=0.001, kernel=rbf..................\n",
      "[CV 5/5; 21/32] END C=100, degree=0, gamma=0.001, kernel=rbf; total time= 4.1min\n",
      "[CV 1/5; 22/32] START C=100, degree=0, gamma=0.001, kernel=poly.................\n",
      "[CV 1/5; 22/32] END C=100, degree=0, gamma=0.001, kernel=poly; total time= 3.6min\n",
      "[CV 2/5; 22/32] START C=100, degree=0, gamma=0.001, kernel=poly.................\n",
      "[CV 2/5; 22/32] END C=100, degree=0, gamma=0.001, kernel=poly; total time= 3.7min\n",
      "[CV 3/5; 22/32] START C=100, degree=0, gamma=0.001, kernel=poly.................\n",
      "[CV 3/5; 22/32] END C=100, degree=0, gamma=0.001, kernel=poly; total time= 3.7min\n",
      "[CV 4/5; 22/32] START C=100, degree=0, gamma=0.001, kernel=poly.................\n",
      "[CV 4/5; 22/32] END C=100, degree=0, gamma=0.001, kernel=poly; total time= 3.7min\n",
      "[CV 5/5; 22/32] START C=100, degree=0, gamma=0.001, kernel=poly.................\n",
      "[CV 5/5; 22/32] END C=100, degree=0, gamma=0.001, kernel=poly; total time= 3.6min\n",
      "[CV 1/5; 23/32] START C=100, degree=0, gamma=0.001, kernel=sigmoid..............\n",
      "[CV 1/5; 23/32] END C=100, degree=0, gamma=0.001, kernel=sigmoid; total time= 3.9min\n",
      "[CV 2/5; 23/32] START C=100, degree=0, gamma=0.001, kernel=sigmoid..............\n",
      "[CV 2/5; 23/32] END C=100, degree=0, gamma=0.001, kernel=sigmoid; total time= 3.9min\n",
      "[CV 3/5; 23/32] START C=100, degree=0, gamma=0.001, kernel=sigmoid..............\n",
      "[CV 3/5; 23/32] END C=100, degree=0, gamma=0.001, kernel=sigmoid; total time= 3.9min\n",
      "[CV 4/5; 23/32] START C=100, degree=0, gamma=0.001, kernel=sigmoid..............\n",
      "[CV 4/5; 23/32] END C=100, degree=0, gamma=0.001, kernel=sigmoid; total time= 3.9min\n",
      "[CV 5/5; 23/32] START C=100, degree=0, gamma=0.001, kernel=sigmoid..............\n",
      "[CV 5/5; 23/32] END C=100, degree=0, gamma=0.001, kernel=sigmoid; total time= 3.9min\n",
      "[CV 1/5; 24/32] START C=100, degree=0, gamma=0.001, kernel=linear...............\n",
      "[CV 1/5; 24/32] END C=100, degree=0, gamma=0.001, kernel=linear; total time= 5.8min\n",
      "[CV 2/5; 24/32] START C=100, degree=0, gamma=0.001, kernel=linear...............\n",
      "[CV 2/5; 24/32] END C=100, degree=0, gamma=0.001, kernel=linear; total time= 6.1min\n",
      "[CV 3/5; 24/32] START C=100, degree=0, gamma=0.001, kernel=linear...............\n",
      "[CV 3/5; 24/32] END C=100, degree=0, gamma=0.001, kernel=linear; total time= 6.0min\n",
      "[CV 4/5; 24/32] START C=100, degree=0, gamma=0.001, kernel=linear...............\n",
      "[CV 4/5; 24/32] END C=100, degree=0, gamma=0.001, kernel=linear; total time= 6.2min\n",
      "[CV 5/5; 24/32] START C=100, degree=0, gamma=0.001, kernel=linear...............\n",
      "[CV 5/5; 24/32] END C=100, degree=0, gamma=0.001, kernel=linear; total time= 6.0min\n",
      "[CV 1/5; 25/32] START C=100, degree=3, gamma=1, kernel=rbf......................\n",
      "[CV 1/5; 25/32] END ....C=100, degree=3, gamma=1, kernel=rbf; total time=11.5min\n",
      "[CV 2/5; 25/32] START C=100, degree=3, gamma=1, kernel=rbf......................\n",
      "[CV 2/5; 25/32] END ....C=100, degree=3, gamma=1, kernel=rbf; total time=11.5min\n",
      "[CV 3/5; 25/32] START C=100, degree=3, gamma=1, kernel=rbf......................\n",
      "[CV 3/5; 25/32] END ....C=100, degree=3, gamma=1, kernel=rbf; total time=11.5min\n",
      "[CV 4/5; 25/32] START C=100, degree=3, gamma=1, kernel=rbf......................\n",
      "[CV 4/5; 25/32] END ....C=100, degree=3, gamma=1, kernel=rbf; total time=11.5min\n",
      "[CV 5/5; 25/32] START C=100, degree=3, gamma=1, kernel=rbf......................\n",
      "[CV 5/5; 25/32] END ....C=100, degree=3, gamma=1, kernel=rbf; total time=11.5min\n",
      "[CV 1/5; 26/32] START C=100, degree=3, gamma=1, kernel=poly.....................\n",
      "[CV 1/5; 26/32] END ...C=100, degree=3, gamma=1, kernel=poly; total time=13.6min\n",
      "[CV 2/5; 26/32] START C=100, degree=3, gamma=1, kernel=poly.....................\n",
      "[CV 2/5; 26/32] END ...C=100, degree=3, gamma=1, kernel=poly; total time=13.7min\n",
      "[CV 3/5; 26/32] START C=100, degree=3, gamma=1, kernel=poly.....................\n",
      "[CV 3/5; 26/32] END ...C=100, degree=3, gamma=1, kernel=poly; total time=13.5min\n",
      "[CV 4/5; 26/32] START C=100, degree=3, gamma=1, kernel=poly.....................\n",
      "[CV 4/5; 26/32] END ...C=100, degree=3, gamma=1, kernel=poly; total time=13.4min\n",
      "[CV 5/5; 26/32] START C=100, degree=3, gamma=1, kernel=poly.....................\n",
      "[CV 5/5; 26/32] END ...C=100, degree=3, gamma=1, kernel=poly; total time=14.1min\n",
      "[CV 1/5; 27/32] START C=100, degree=3, gamma=1, kernel=sigmoid..................\n",
      "[CV 1/5; 27/32] END C=100, degree=3, gamma=1, kernel=sigmoid; total time=13.6min\n",
      "[CV 2/5; 27/32] START C=100, degree=3, gamma=1, kernel=sigmoid..................\n",
      "[CV 2/5; 27/32] END C=100, degree=3, gamma=1, kernel=sigmoid; total time=13.0min\n",
      "[CV 3/5; 27/32] START C=100, degree=3, gamma=1, kernel=sigmoid..................\n",
      "[CV 3/5; 27/32] END C=100, degree=3, gamma=1, kernel=sigmoid; total time=12.8min\n",
      "[CV 4/5; 27/32] START C=100, degree=3, gamma=1, kernel=sigmoid..................\n",
      "[CV 4/5; 27/32] END C=100, degree=3, gamma=1, kernel=sigmoid; total time=10.8min\n",
      "[CV 5/5; 27/32] START C=100, degree=3, gamma=1, kernel=sigmoid..................\n",
      "[CV 5/5; 27/32] END C=100, degree=3, gamma=1, kernel=sigmoid; total time=12.0min\n",
      "[CV 1/5; 28/32] START C=100, degree=3, gamma=1, kernel=linear...................\n",
      "[CV 1/5; 28/32] END .C=100, degree=3, gamma=1, kernel=linear; total time= 5.8min\n",
      "[CV 2/5; 28/32] START C=100, degree=3, gamma=1, kernel=linear...................\n",
      "[CV 2/5; 28/32] END .C=100, degree=3, gamma=1, kernel=linear; total time= 6.1min\n",
      "[CV 3/5; 28/32] START C=100, degree=3, gamma=1, kernel=linear...................\n",
      "[CV 3/5; 28/32] END .C=100, degree=3, gamma=1, kernel=linear; total time= 6.0min\n",
      "[CV 4/5; 28/32] START C=100, degree=3, gamma=1, kernel=linear...................\n",
      "[CV 4/5; 28/32] END .C=100, degree=3, gamma=1, kernel=linear; total time= 6.3min\n",
      "[CV 5/5; 28/32] START C=100, degree=3, gamma=1, kernel=linear...................\n",
      "[CV 5/5; 28/32] END .C=100, degree=3, gamma=1, kernel=linear; total time= 6.0min\n",
      "[CV 1/5; 29/32] START C=100, degree=3, gamma=0.001, kernel=rbf..................\n",
      "[CV 1/5; 29/32] END C=100, degree=3, gamma=0.001, kernel=rbf; total time= 4.0min\n",
      "[CV 2/5; 29/32] START C=100, degree=3, gamma=0.001, kernel=rbf..................\n",
      "[CV 2/5; 29/32] END C=100, degree=3, gamma=0.001, kernel=rbf; total time= 4.1min\n",
      "[CV 3/5; 29/32] START C=100, degree=3, gamma=0.001, kernel=rbf..................\n",
      "[CV 3/5; 29/32] END C=100, degree=3, gamma=0.001, kernel=rbf; total time= 4.0min\n",
      "[CV 4/5; 29/32] START C=100, degree=3, gamma=0.001, kernel=rbf..................\n",
      "[CV 4/5; 29/32] END C=100, degree=3, gamma=0.001, kernel=rbf; total time= 4.0min\n",
      "[CV 5/5; 29/32] START C=100, degree=3, gamma=0.001, kernel=rbf..................\n",
      "[CV 5/5; 29/32] END C=100, degree=3, gamma=0.001, kernel=rbf; total time= 4.0min\n",
      "[CV 1/5; 30/32] START C=100, degree=3, gamma=0.001, kernel=poly.................\n",
      "[CV 1/5; 30/32] END C=100, degree=3, gamma=0.001, kernel=poly; total time= 3.7min\n",
      "[CV 2/5; 30/32] START C=100, degree=3, gamma=0.001, kernel=poly.................\n",
      "[CV 2/5; 30/32] END C=100, degree=3, gamma=0.001, kernel=poly; total time= 3.7min\n",
      "[CV 3/5; 30/32] START C=100, degree=3, gamma=0.001, kernel=poly.................\n",
      "[CV 3/5; 30/32] END C=100, degree=3, gamma=0.001, kernel=poly; total time= 3.7min\n",
      "[CV 4/5; 30/32] START C=100, degree=3, gamma=0.001, kernel=poly.................\n",
      "[CV 4/5; 30/32] END C=100, degree=3, gamma=0.001, kernel=poly; total time= 3.7min\n",
      "[CV 5/5; 30/32] START C=100, degree=3, gamma=0.001, kernel=poly.................\n",
      "[CV 5/5; 30/32] END C=100, degree=3, gamma=0.001, kernel=poly; total time= 3.7min\n",
      "[CV 1/5; 31/32] START C=100, degree=3, gamma=0.001, kernel=sigmoid..............\n",
      "[CV 1/5; 31/32] END C=100, degree=3, gamma=0.001, kernel=sigmoid; total time= 3.9min\n",
      "[CV 2/5; 31/32] START C=100, degree=3, gamma=0.001, kernel=sigmoid..............\n",
      "[CV 2/5; 31/32] END C=100, degree=3, gamma=0.001, kernel=sigmoid; total time= 3.9min\n",
      "[CV 3/5; 31/32] START C=100, degree=3, gamma=0.001, kernel=sigmoid..............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 31/32] END C=100, degree=3, gamma=0.001, kernel=sigmoid; total time= 3.9min\n",
      "[CV 4/5; 31/32] START C=100, degree=3, gamma=0.001, kernel=sigmoid..............\n",
      "[CV 4/5; 31/32] END C=100, degree=3, gamma=0.001, kernel=sigmoid; total time= 3.9min\n",
      "[CV 5/5; 31/32] START C=100, degree=3, gamma=0.001, kernel=sigmoid..............\n",
      "[CV 5/5; 31/32] END C=100, degree=3, gamma=0.001, kernel=sigmoid; total time= 3.9min\n",
      "[CV 1/5; 32/32] START C=100, degree=3, gamma=0.001, kernel=linear...............\n",
      "[CV 1/5; 32/32] END C=100, degree=3, gamma=0.001, kernel=linear; total time= 5.8min\n",
      "[CV 2/5; 32/32] START C=100, degree=3, gamma=0.001, kernel=linear...............\n",
      "[CV 2/5; 32/32] END C=100, degree=3, gamma=0.001, kernel=linear; total time= 6.1min\n",
      "[CV 3/5; 32/32] START C=100, degree=3, gamma=0.001, kernel=linear...............\n",
      "[CV 3/5; 32/32] END C=100, degree=3, gamma=0.001, kernel=linear; total time= 6.0min\n",
      "[CV 4/5; 32/32] START C=100, degree=3, gamma=0.001, kernel=linear...............\n",
      "[CV 4/5; 32/32] END C=100, degree=3, gamma=0.001, kernel=linear; total time= 6.2min\n",
      "[CV 5/5; 32/32] START C=100, degree=3, gamma=0.001, kernel=linear...............\n",
      "[CV 5/5; 32/32] END C=100, degree=3, gamma=0.001, kernel=linear; total time= 6.0min\n",
      "{'C': 100, 'degree': 0, 'gamma': 1, 'kernel': 'rbf'}\n",
      "SVC(C=100, degree=0, gamma=1)\n"
     ]
    }
   ],
   "source": [
    "## get running time\n",
    "%time\n",
    "\n",
    "# hyper prameter tuning for SVC:\n",
    "from sklearn.model_selection import GridSearchCV\n",
    " \n",
    "# defining parameter range\n",
    "param_grid = {'C': [0.1, 100], 'gamma': [1,0.001], 'kernel':['rbf','poly','sigmoid','linear'], 'degree':[0, 3]}\n",
    "grid = GridSearchCV(SVC(),param_grid,scoring='accuracy', verbose=10)\n",
    "grid.fit(tfidf_train,y_train)\n",
    " \n",
    "\n",
    "# print best parameter after tuning\n",
    "print(grid.best_params_)\n",
    " \n",
    "# print how our model looks after hyper-parameter tuning\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e1f024ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'C': 0.1, 'degree': 0, 'gamma': 1, 'kernel': ...</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.282502</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'C': 0.1, 'degree': 0, 'gamma': 1, 'kernel': ...</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.277092</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'C': 0.1, 'degree': 0, 'gamma': 1, 'kernel': ...</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.387631</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'C': 0.1, 'degree': 0, 'gamma': 1, 'kernel': ...</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.391356</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'C': 0.1, 'degree': 0, 'gamma': 0.001, 'kerne...</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.277092</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'C': 0.1, 'degree': 0, 'gamma': 0.001, 'kerne...</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.277092</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'C': 0.1, 'degree': 0, 'gamma': 0.001, 'kerne...</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.277092</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'C': 0.1, 'degree': 0, 'gamma': 0.001, 'kerne...</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.391356</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'C': 0.1, 'degree': 3, 'gamma': 1, 'kernel': ...</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.282502</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'C': 0.1, 'degree': 3, 'gamma': 1, 'kernel': ...</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.277675</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'C': 0.1, 'degree': 3, 'gamma': 1, 'kernel': ...</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.387631</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'C': 0.1, 'degree': 3, 'gamma': 1, 'kernel': ...</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.391356</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'C': 0.1, 'degree': 3, 'gamma': 0.001, 'kerne...</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.277092</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'C': 0.1, 'degree': 3, 'gamma': 0.001, 'kerne...</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.277092</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'C': 0.1, 'degree': 3, 'gamma': 0.001, 'kerne...</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.277092</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'C': 0.1, 'degree': 3, 'gamma': 0.001, 'kerne...</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.391356</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'C': 100, 'degree': 0, 'gamma': 1, 'kernel': ...</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.602877</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'C': 100, 'degree': 0, 'gamma': 1, 'kernel': ...</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.277092</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'C': 100, 'degree': 0, 'gamma': 1, 'kernel': ...</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.527424</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'C': 100, 'degree': 0, 'gamma': 1, 'kernel': ...</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.559238</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{'C': 100, 'degree': 0, 'gamma': 0.001, 'kerne...</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.491819</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>{'C': 100, 'degree': 0, 'gamma': 0.001, 'kerne...</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.277092</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>{'C': 100, 'degree': 0, 'gamma': 0.001, 'kerne...</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.391356</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{'C': 100, 'degree': 0, 'gamma': 0.001, 'kerne...</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.559238</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>{'C': 100, 'degree': 3, 'gamma': 1, 'kernel': ...</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.602877</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>{'C': 100, 'degree': 3, 'gamma': 1, 'kernel': ...</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.396896</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>{'C': 100, 'degree': 3, 'gamma': 1, 'kernel': ...</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.527424</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>{'C': 100, 'degree': 3, 'gamma': 1, 'kernel': ...</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.559238</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>{'C': 100, 'degree': 3, 'gamma': 0.001, 'kerne...</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.491819</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>{'C': 100, 'degree': 3, 'gamma': 0.001, 'kerne...</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.277092</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>{'C': 100, 'degree': 3, 'gamma': 0.001, 'kerne...</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.391356</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>{'C': 100, 'degree': 3, 'gamma': 0.001, 'kerne...</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.559238</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               params param_kernel  \\\n",
       "0   {'C': 0.1, 'degree': 0, 'gamma': 1, 'kernel': ...          rbf   \n",
       "1   {'C': 0.1, 'degree': 0, 'gamma': 1, 'kernel': ...         poly   \n",
       "2   {'C': 0.1, 'degree': 0, 'gamma': 1, 'kernel': ...      sigmoid   \n",
       "3   {'C': 0.1, 'degree': 0, 'gamma': 1, 'kernel': ...       linear   \n",
       "4   {'C': 0.1, 'degree': 0, 'gamma': 0.001, 'kerne...          rbf   \n",
       "5   {'C': 0.1, 'degree': 0, 'gamma': 0.001, 'kerne...         poly   \n",
       "6   {'C': 0.1, 'degree': 0, 'gamma': 0.001, 'kerne...      sigmoid   \n",
       "7   {'C': 0.1, 'degree': 0, 'gamma': 0.001, 'kerne...       linear   \n",
       "8   {'C': 0.1, 'degree': 3, 'gamma': 1, 'kernel': ...          rbf   \n",
       "9   {'C': 0.1, 'degree': 3, 'gamma': 1, 'kernel': ...         poly   \n",
       "10  {'C': 0.1, 'degree': 3, 'gamma': 1, 'kernel': ...      sigmoid   \n",
       "11  {'C': 0.1, 'degree': 3, 'gamma': 1, 'kernel': ...       linear   \n",
       "12  {'C': 0.1, 'degree': 3, 'gamma': 0.001, 'kerne...          rbf   \n",
       "13  {'C': 0.1, 'degree': 3, 'gamma': 0.001, 'kerne...         poly   \n",
       "14  {'C': 0.1, 'degree': 3, 'gamma': 0.001, 'kerne...      sigmoid   \n",
       "15  {'C': 0.1, 'degree': 3, 'gamma': 0.001, 'kerne...       linear   \n",
       "16  {'C': 100, 'degree': 0, 'gamma': 1, 'kernel': ...          rbf   \n",
       "17  {'C': 100, 'degree': 0, 'gamma': 1, 'kernel': ...         poly   \n",
       "18  {'C': 100, 'degree': 0, 'gamma': 1, 'kernel': ...      sigmoid   \n",
       "19  {'C': 100, 'degree': 0, 'gamma': 1, 'kernel': ...       linear   \n",
       "20  {'C': 100, 'degree': 0, 'gamma': 0.001, 'kerne...          rbf   \n",
       "21  {'C': 100, 'degree': 0, 'gamma': 0.001, 'kerne...         poly   \n",
       "22  {'C': 100, 'degree': 0, 'gamma': 0.001, 'kerne...      sigmoid   \n",
       "23  {'C': 100, 'degree': 0, 'gamma': 0.001, 'kerne...       linear   \n",
       "24  {'C': 100, 'degree': 3, 'gamma': 1, 'kernel': ...          rbf   \n",
       "25  {'C': 100, 'degree': 3, 'gamma': 1, 'kernel': ...         poly   \n",
       "26  {'C': 100, 'degree': 3, 'gamma': 1, 'kernel': ...      sigmoid   \n",
       "27  {'C': 100, 'degree': 3, 'gamma': 1, 'kernel': ...       linear   \n",
       "28  {'C': 100, 'degree': 3, 'gamma': 0.001, 'kerne...          rbf   \n",
       "29  {'C': 100, 'degree': 3, 'gamma': 0.001, 'kerne...         poly   \n",
       "30  {'C': 100, 'degree': 3, 'gamma': 0.001, 'kerne...      sigmoid   \n",
       "31  {'C': 100, 'degree': 3, 'gamma': 0.001, 'kerne...       linear   \n",
       "\n",
       "    mean_test_score  rank_test_score  \n",
       "0          0.282502               20  \n",
       "1          0.277092               23  \n",
       "2          0.387631               18  \n",
       "3          0.391356               12  \n",
       "4          0.277092               23  \n",
       "5          0.277092               23  \n",
       "6          0.277092               23  \n",
       "7          0.391356               12  \n",
       "8          0.282502               20  \n",
       "9          0.277675               22  \n",
       "10         0.387631               18  \n",
       "11         0.391356               12  \n",
       "12         0.277092               23  \n",
       "13         0.277092               23  \n",
       "14         0.277092               23  \n",
       "15         0.391356               12  \n",
       "16         0.602877                1  \n",
       "17         0.277092               23  \n",
       "18         0.527424                7  \n",
       "19         0.559238                3  \n",
       "20         0.491819                9  \n",
       "21         0.277092               23  \n",
       "22         0.391356               12  \n",
       "23         0.559238                3  \n",
       "24         0.602877                1  \n",
       "25         0.396896               11  \n",
       "26         0.527424                7  \n",
       "27         0.559238                3  \n",
       "28         0.491819                9  \n",
       "29         0.277092               23  \n",
       "30         0.391356               12  \n",
       "31         0.559238                3  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=pd.DataFrame(grid.cv_results_)\n",
    "result[['params','param_kernel', 'mean_test_score', 'rank_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2d48d5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Extremely Negative       0.61      0.42      0.50      1342\n",
      "Extremely Positive       0.64      0.46      0.53      1674\n",
      "          Negative       0.48      0.48      0.48      2466\n",
      "           Neutral       0.54      0.69      0.61      1939\n",
      "          Positive       0.48      0.53      0.50      2869\n",
      "\n",
      "          accuracy                           0.52     10290\n",
      "         macro avg       0.55      0.52      0.52     10290\n",
      "      weighted avg       0.53      0.52      0.52     10290\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5232264334305151"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F1 0.52, run time short\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(tfidf_train, y_train)\n",
    "y_pred = rf.predict(tfidf_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "642e2941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV 1/5; 1/6] START max_depth=8, n_estimators=64................................\n",
      "[CV 1/5; 1/6] END ..............max_depth=8, n_estimators=64; total time=   0.8s\n",
      "[CV 2/5; 1/6] START max_depth=8, n_estimators=64................................\n",
      "[CV 2/5; 1/6] END ..............max_depth=8, n_estimators=64; total time=   0.8s\n",
      "[CV 3/5; 1/6] START max_depth=8, n_estimators=64................................\n",
      "[CV 3/5; 1/6] END ..............max_depth=8, n_estimators=64; total time=   0.8s\n",
      "[CV 4/5; 1/6] START max_depth=8, n_estimators=64................................\n",
      "[CV 4/5; 1/6] END ..............max_depth=8, n_estimators=64; total time=   0.8s\n",
      "[CV 5/5; 1/6] START max_depth=8, n_estimators=64................................\n",
      "[CV 5/5; 1/6] END ..............max_depth=8, n_estimators=64; total time=   0.8s\n",
      "[CV 1/5; 2/6] START max_depth=8, n_estimators=256...............................\n",
      "[CV 1/5; 2/6] END .............max_depth=8, n_estimators=256; total time=   3.2s\n",
      "[CV 2/5; 2/6] START max_depth=8, n_estimators=256...............................\n",
      "[CV 2/5; 2/6] END .............max_depth=8, n_estimators=256; total time=   3.3s\n",
      "[CV 3/5; 2/6] START max_depth=8, n_estimators=256...............................\n",
      "[CV 3/5; 2/6] END .............max_depth=8, n_estimators=256; total time=   2.9s\n",
      "[CV 4/5; 2/6] START max_depth=8, n_estimators=256...............................\n",
      "[CV 4/5; 2/6] END .............max_depth=8, n_estimators=256; total time=   3.0s\n",
      "[CV 5/5; 2/6] START max_depth=8, n_estimators=256...............................\n",
      "[CV 5/5; 2/6] END .............max_depth=8, n_estimators=256; total time=   3.0s\n",
      "[CV 1/5; 3/6] START max_depth=8, n_estimators=512...............................\n",
      "[CV 1/5; 3/6] END .............max_depth=8, n_estimators=512; total time=   5.9s\n",
      "[CV 2/5; 3/6] START max_depth=8, n_estimators=512...............................\n",
      "[CV 2/5; 3/6] END .............max_depth=8, n_estimators=512; total time=   5.8s\n",
      "[CV 3/5; 3/6] START max_depth=8, n_estimators=512...............................\n",
      "[CV 3/5; 3/6] END .............max_depth=8, n_estimators=512; total time=   5.6s\n",
      "[CV 4/5; 3/6] START max_depth=8, n_estimators=512...............................\n",
      "[CV 4/5; 3/6] END .............max_depth=8, n_estimators=512; total time=   6.5s\n",
      "[CV 5/5; 3/6] START max_depth=8, n_estimators=512...............................\n",
      "[CV 5/5; 3/6] END .............max_depth=8, n_estimators=512; total time=   6.8s\n",
      "[CV 1/5; 4/6] START max_depth=64, n_estimators=64...............................\n",
      "[CV 1/5; 4/6] END .............max_depth=64, n_estimators=64; total time=  14.1s\n",
      "[CV 2/5; 4/6] START max_depth=64, n_estimators=64...............................\n",
      "[CV 2/5; 4/6] END .............max_depth=64, n_estimators=64; total time=  16.2s\n",
      "[CV 3/5; 4/6] START max_depth=64, n_estimators=64...............................\n",
      "[CV 3/5; 4/6] END .............max_depth=64, n_estimators=64; total time=  14.6s\n",
      "[CV 4/5; 4/6] START max_depth=64, n_estimators=64...............................\n",
      "[CV 4/5; 4/6] END .............max_depth=64, n_estimators=64; total time=   9.6s\n",
      "[CV 5/5; 4/6] START max_depth=64, n_estimators=64...............................\n",
      "[CV 5/5; 4/6] END .............max_depth=64, n_estimators=64; total time=  10.4s\n",
      "[CV 1/5; 5/6] START max_depth=64, n_estimators=256..............................\n",
      "[CV 1/5; 5/6] END ............max_depth=64, n_estimators=256; total time=  39.9s\n",
      "[CV 2/5; 5/6] START max_depth=64, n_estimators=256..............................\n",
      "[CV 2/5; 5/6] END ............max_depth=64, n_estimators=256; total time=  42.5s\n",
      "[CV 3/5; 5/6] START max_depth=64, n_estimators=256..............................\n",
      "[CV 3/5; 5/6] END ............max_depth=64, n_estimators=256; total time=  44.8s\n",
      "[CV 4/5; 5/6] START max_depth=64, n_estimators=256..............................\n",
      "[CV 4/5; 5/6] END ............max_depth=64, n_estimators=256; total time=  39.9s\n",
      "[CV 5/5; 5/6] START max_depth=64, n_estimators=256..............................\n",
      "[CV 5/5; 5/6] END ............max_depth=64, n_estimators=256; total time=  38.1s\n",
      "[CV 1/5; 6/6] START max_depth=64, n_estimators=512..............................\n",
      "[CV 1/5; 6/6] END ............max_depth=64, n_estimators=512; total time= 1.3min\n",
      "[CV 2/5; 6/6] START max_depth=64, n_estimators=512..............................\n",
      "[CV 2/5; 6/6] END ............max_depth=64, n_estimators=512; total time= 1.3min\n",
      "[CV 3/5; 6/6] START max_depth=64, n_estimators=512..............................\n",
      "[CV 3/5; 6/6] END ............max_depth=64, n_estimators=512; total time= 1.3min\n",
      "[CV 4/5; 6/6] START max_depth=64, n_estimators=512..............................\n",
      "[CV 4/5; 6/6] END ............max_depth=64, n_estimators=512; total time= 1.4min\n",
      "[CV 5/5; 6/6] START max_depth=64, n_estimators=512..............................\n",
      "[CV 5/5; 6/6] END ............max_depth=64, n_estimators=512; total time= 1.3min\n",
      "Best: [0.30194061 0.29675706 0.29481324 0.49868769 0.50322326 0.50536148], using {'max_depth': 64, 'n_estimators': 512}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.745753</td>\n",
       "      <td>0.012255</td>\n",
       "      <td>0.084325</td>\n",
       "      <td>0.002892</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 64}</td>\n",
       "      <td>0.301749</td>\n",
       "      <td>0.301263</td>\n",
       "      <td>0.304228</td>\n",
       "      <td>0.300664</td>\n",
       "      <td>0.301798</td>\n",
       "      <td>0.301941</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.830138</td>\n",
       "      <td>0.149389</td>\n",
       "      <td>0.252849</td>\n",
       "      <td>0.012852</td>\n",
       "      <td>8</td>\n",
       "      <td>256</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 256}</td>\n",
       "      <td>0.295109</td>\n",
       "      <td>0.298348</td>\n",
       "      <td>0.295966</td>\n",
       "      <td>0.297748</td>\n",
       "      <td>0.296614</td>\n",
       "      <td>0.296757</td>\n",
       "      <td>0.001173</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.583545</td>\n",
       "      <td>0.419258</td>\n",
       "      <td>0.516784</td>\n",
       "      <td>0.073685</td>\n",
       "      <td>8</td>\n",
       "      <td>512</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 512}</td>\n",
       "      <td>0.294137</td>\n",
       "      <td>0.295109</td>\n",
       "      <td>0.294670</td>\n",
       "      <td>0.295480</td>\n",
       "      <td>0.294670</td>\n",
       "      <td>0.294813</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.730127</td>\n",
       "      <td>2.498740</td>\n",
       "      <td>0.256962</td>\n",
       "      <td>0.093112</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>{'max_depth': 64, 'n_estimators': 64}</td>\n",
       "      <td>0.502430</td>\n",
       "      <td>0.501944</td>\n",
       "      <td>0.493115</td>\n",
       "      <td>0.497813</td>\n",
       "      <td>0.498137</td>\n",
       "      <td>0.498688</td>\n",
       "      <td>0.003368</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.335381</td>\n",
       "      <td>2.319093</td>\n",
       "      <td>0.709170</td>\n",
       "      <td>0.038180</td>\n",
       "      <td>64</td>\n",
       "      <td>256</td>\n",
       "      <td>{'max_depth': 64, 'n_estimators': 256}</td>\n",
       "      <td>0.509556</td>\n",
       "      <td>0.504535</td>\n",
       "      <td>0.501215</td>\n",
       "      <td>0.502835</td>\n",
       "      <td>0.497975</td>\n",
       "      <td>0.503223</td>\n",
       "      <td>0.003835</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>77.415099</td>\n",
       "      <td>2.169417</td>\n",
       "      <td>1.358657</td>\n",
       "      <td>0.049685</td>\n",
       "      <td>64</td>\n",
       "      <td>512</td>\n",
       "      <td>{'max_depth': 64, 'n_estimators': 512}</td>\n",
       "      <td>0.511500</td>\n",
       "      <td>0.506317</td>\n",
       "      <td>0.504779</td>\n",
       "      <td>0.504131</td>\n",
       "      <td>0.500081</td>\n",
       "      <td>0.505361</td>\n",
       "      <td>0.003697</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.745753      0.012255         0.084325        0.002892   \n",
       "1       2.830138      0.149389         0.252849        0.012852   \n",
       "2       5.583545      0.419258         0.516784        0.073685   \n",
       "3      12.730127      2.498740         0.256962        0.093112   \n",
       "4      40.335381      2.319093         0.709170        0.038180   \n",
       "5      77.415099      2.169417         1.358657        0.049685   \n",
       "\n",
       "  param_max_depth param_n_estimators                                  params  \\\n",
       "0               8                 64    {'max_depth': 8, 'n_estimators': 64}   \n",
       "1               8                256   {'max_depth': 8, 'n_estimators': 256}   \n",
       "2               8                512   {'max_depth': 8, 'n_estimators': 512}   \n",
       "3              64                 64   {'max_depth': 64, 'n_estimators': 64}   \n",
       "4              64                256  {'max_depth': 64, 'n_estimators': 256}   \n",
       "5              64                512  {'max_depth': 64, 'n_estimators': 512}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           0.301749           0.301263           0.304228           0.300664   \n",
       "1           0.295109           0.298348           0.295966           0.297748   \n",
       "2           0.294137           0.295109           0.294670           0.295480   \n",
       "3           0.502430           0.501944           0.493115           0.497813   \n",
       "4           0.509556           0.504535           0.501215           0.502835   \n",
       "5           0.511500           0.506317           0.504779           0.504131   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           0.301798         0.301941        0.001215                4  \n",
       "1           0.296614         0.296757        0.001173                5  \n",
       "2           0.294670         0.294813        0.000454                6  \n",
       "3           0.498137         0.498688        0.003368                3  \n",
       "4           0.497975         0.503223        0.003835                2  \n",
       "5           0.500081         0.505361        0.003697                1  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Searching for better hyperparameters\n",
    "# Define Parameters\n",
    "max_depth=[8, 64]\n",
    "n_estimators = [64, 256, 512]\n",
    "param_grid = {'max_depth': max_depth, \n",
    "              'n_estimators': n_estimators}\n",
    "\n",
    "# Build the grid search\n",
    "dfrst = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state = 1)\n",
    "grid_RF = GridSearchCV(estimator=dfrst, param_grid=param_grid, cv = 5, scoring='accuracy', verbose=10)\n",
    "grid_results = grid_RF.fit(tfidf_train,y_train)\n",
    "\n",
    "# Summarize the results in a readable format\n",
    "print(\"Best: {0}, using {1}\".format(grid_results.cv_results_['mean_test_score'], grid_results.best_params_))\n",
    "results_RF = pd.DataFrame(grid_results.cv_results_)\n",
    "results_RF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
