{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpringBoard Capstone2: Coronavirus Tweets Sentiment Analysis\n",
    "\n",
    "    Data from Kaggle.com: https://www.kaggle.com/datatattle/covid-19-nlp-text-classification/metadata\n",
    "## Multi_Dense_Layer used for modeling, classes reduced to 3. \n",
    "    Extremely tweets were categoried as positive or negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-01-19T07:59:21.844453Z",
     "iopub.status.busy": "2022-01-19T07:59:21.844086Z",
     "iopub.status.idle": "2022-01-19T07:59:21.855644Z",
     "shell.execute_reply": "2022-01-19T07:59:21.854673Z",
     "shell.execute_reply.started": "2022-01-19T07:59:21.844409Z"
    }
   },
   "outputs": [],
   "source": [
    "# ## Cell used in Kaggles webpage\n",
    "\n",
    "# # This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# # For example, here's several helpful packages to load\n",
    "\n",
    "# import numpy as np # linear algebra\n",
    "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# # Input data files are available in the read-only \"../input/\" directory\n",
    "# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# # import os\n",
    "# # for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "# #     for filename in filenames:\n",
    "# #         print(os.path.join(dirname, filename))\n",
    "\n",
    "# # # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# # # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T08:01:26.412695Z",
     "iopub.status.busy": "2022-01-19T08:01:26.412398Z",
     "iopub.status.idle": "2022-01-19T08:01:26.420148Z",
     "shell.execute_reply": "2022-01-19T08:01:26.419204Z",
     "shell.execute_reply.started": "2022-01-19T08:01:26.412665Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# from wordcloud import WordCloud\n",
    "import re\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report,ConfusionMatrixDisplay\n",
    "\n",
    "### references: \n",
    "### https://www.analyticsvidhya.com/blog/2021/06/twitter-sentiment-analysis-a-nlp-use-case-for-beginners/\n",
    "### https://github.com/mengyanl/Twitter_Sentiment_Analysis/blob/main/notebooks/1.5%20Twitter%20Sentiment%20Analysis%20-%20Bag%20of%20Words%20(Code%20Submission).ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T07:59:21.869865Z",
     "iopub.status.busy": "2022-01-19T07:59:21.869339Z",
     "iopub.status.idle": "2022-01-19T07:59:22.276649Z",
     "shell.execute_reply": "2022-01-19T07:59:22.275769Z",
     "shell.execute_reply.started": "2022-01-19T07:59:21.869832Z"
    }
   },
   "outputs": [],
   "source": [
    "tweet_whole_train = pd.read_csv('/Users/Ling/Desktop/01_Springboard/Corona_Tweet/Data/Corona_NLP_train.csv', index_col = 0)\n",
    "print(tweet_whole_train.info())\n",
    "test = pd.read_csv('/Users/Ling/Desktop/01_Springboard/Corona_Tweet/Data/Corona_NLP_test.csv', index_col = 0)\n",
    "print(test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T07:59:22.279515Z",
     "iopub.status.busy": "2022-01-19T07:59:22.279030Z",
     "iopub.status.idle": "2022-01-19T07:59:22.283652Z",
     "shell.execute_reply": "2022-01-19T07:59:22.282743Z",
     "shell.execute_reply.started": "2022-01-19T07:59:22.279461Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[15,7])\n",
    "sns.histplot(data=tweet_whole_train, x = 'TweetAt', hue = 'Sentiment', multiple='dodge')\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T07:59:22.285548Z",
     "iopub.status.busy": "2022-01-19T07:59:22.285254Z",
     "iopub.status.idle": "2022-01-19T07:59:22.294982Z",
     "shell.execute_reply": "2022-01-19T07:59:22.294278Z",
     "shell.execute_reply.started": "2022-01-19T07:59:22.285511Z"
    }
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=[15,7])\n",
    "# sns.histplot(data=test, x = 'TweetAt', hue = 'Sentiment', multiple='dodge')\n",
    "# plt.xticks(rotation = 90)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T07:59:22.296781Z",
     "iopub.status.busy": "2022-01-19T07:59:22.296284Z",
     "iopub.status.idle": "2022-01-19T07:59:22.307089Z",
     "shell.execute_reply": "2022-01-19T07:59:22.306260Z",
     "shell.execute_reply.started": "2022-01-19T07:59:22.296723Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(tweet_whole_train['Location'].unique()))\n",
    "print(len(test['Location'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T07:59:22.308918Z",
     "iopub.status.busy": "2022-01-19T07:59:22.308599Z",
     "iopub.status.idle": "2022-01-19T07:59:22.321920Z",
     "shell.execute_reply": "2022-01-19T07:59:22.321157Z",
     "shell.execute_reply.started": "2022-01-19T07:59:22.308879Z"
    }
   },
   "outputs": [],
   "source": [
    "tweet = tweet_whole_train[['OriginalTweet', 'Sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T07:59:22.323993Z",
     "iopub.status.busy": "2022-01-19T07:59:22.323339Z",
     "iopub.status.idle": "2022-01-19T07:59:22.544580Z",
     "shell.execute_reply": "2022-01-19T07:59:22.543683Z",
     "shell.execute_reply.started": "2022-01-19T07:59:22.323944Z"
    }
   },
   "outputs": [],
   "source": [
    "order = ['Extremely Negative', 'Negative', 'Neutral','Positive','Extremely Positive']\n",
    "sns.countplot(x = 'Sentiment', data = tweet, order = order, palette=['#432371',\"#FAAE7B\",\"#7fcdbb\"])\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T07:59:22.546611Z",
     "iopub.status.busy": "2022-01-19T07:59:22.546140Z",
     "iopub.status.idle": "2022-01-19T07:59:22.598098Z",
     "shell.execute_reply": "2022-01-19T07:59:22.597302Z",
     "shell.execute_reply.started": "2022-01-19T07:59:22.546567Z"
    }
   },
   "outputs": [],
   "source": [
    "# lower case all text\n",
    "tweet['OriginalTweet'] = tweet['OriginalTweet'].str.lower()\n",
    "test['OriginalTweet'] = test['OriginalTweet'].str.lower()\n",
    "\n",
    "print('TRAIN DATA \\n', tweet['OriginalTweet'].head())\n",
    "print('\\n TEST DATA \\n', test['OriginalTweet'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T07:59:22.600755Z",
     "iopub.status.busy": "2022-01-19T07:59:22.600370Z",
     "iopub.status.idle": "2022-01-19T07:59:22.952433Z",
     "shell.execute_reply": "2022-01-19T07:59:22.951627Z",
     "shell.execute_reply.started": "2022-01-19T07:59:22.600707Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_at_signs(text):\n",
    "    return \" \".join([word for word in str(text).split() if not word.startswith('@')])\n",
    "tweet['OriginalTweet'] = tweet['OriginalTweet'].apply(lambda text: remove_at_signs(text))\n",
    "test['OriginalTweet'] = test['OriginalTweet'].apply(lambda text: remove_at_signs(text))\n",
    "\n",
    "print('TRAIN DATA \\n', tweet['OriginalTweet'].head())\n",
    "print('\\n TEST DATA \\n', test['OriginalTweet'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T07:59:22.954011Z",
     "iopub.status.busy": "2022-01-19T07:59:22.953767Z",
     "iopub.status.idle": "2022-01-19T07:59:24.203423Z",
     "shell.execute_reply": "2022-01-19T07:59:24.202523Z",
     "shell.execute_reply.started": "2022-01-19T07:59:22.953982Z"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "def cleaning_repeating_char(text):\n",
    "    cl = ''.join(ch for ch, _ in itertools.groupby(text))\n",
    "    return cl\n",
    "tweet['OriginalTweet'] = tweet['OriginalTweet'].apply(lambda x: cleaning_repeating_char(x))\n",
    "test['OriginalTweet'] = test['OriginalTweet'].apply(lambda x: cleaning_repeating_char(x))\n",
    "\n",
    "print('TRAIN DATA \\n', tweet['OriginalTweet'].head())\n",
    "print('\\n TEST DATA \\n', test['OriginalTweet'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T07:59:24.205089Z",
     "iopub.status.busy": "2022-01-19T07:59:24.204790Z",
     "iopub.status.idle": "2022-01-19T07:59:24.477641Z",
     "shell.execute_reply": "2022-01-19T07:59:24.476583Z",
     "shell.execute_reply.started": "2022-01-19T07:59:24.205048Z"
    }
   },
   "outputs": [],
   "source": [
    "def cleaning_URLs(data):\n",
    "    return re.sub('[^ ]+\\.[^ ]+' , ' url', data)\n",
    "tweet['OriginalTweet'] = tweet['OriginalTweet'].apply(lambda x: cleaning_URLs(x))\n",
    "test['OriginalTweet'] = test['OriginalTweet'].apply(lambda x: cleaning_URLs(x))\n",
    "\n",
    "print('TRAIN DATA \\n', tweet['OriginalTweet'].head())\n",
    "print('\\n TEST DATA \\n', test['OriginalTweet'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T07:59:24.479693Z",
     "iopub.status.busy": "2022-01-19T07:59:24.479390Z",
     "iopub.status.idle": "2022-01-19T07:59:24.818295Z",
     "shell.execute_reply": "2022-01-19T07:59:24.817320Z",
     "shell.execute_reply.started": "2022-01-19T07:59:24.479652Z"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "english_punctuations = string.punctuation\n",
    "punctuations_list = english_punctuations\n",
    "def cleaning_punctuations(text):\n",
    "    translator = str.maketrans(' ', ' ', punctuations_list)\n",
    "    return text.translate(translator)\n",
    "tweet['OriginalTweet']= tweet['OriginalTweet'].apply(lambda x: cleaning_punctuations(x))\n",
    "test['OriginalTweet']= test['OriginalTweet'].apply(lambda x: cleaning_punctuations(x))\n",
    "\n",
    "print('TRAIN DATA \\n', tweet['OriginalTweet'].head())\n",
    "print('\\n TEST DATA \\n', test['OriginalTweet'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T07:59:24.820148Z",
     "iopub.status.busy": "2022-01-19T07:59:24.819739Z",
     "iopub.status.idle": "2022-01-19T07:59:25.070400Z",
     "shell.execute_reply": "2022-01-19T07:59:25.069519Z",
     "shell.execute_reply.started": "2022-01-19T07:59:24.820105Z"
    }
   },
   "outputs": [],
   "source": [
    "def cleaning_numbers(data):\n",
    "    return re.sub('[0-9]+', '', data)\n",
    "tweet['OriginalTweet'] = tweet['OriginalTweet'].apply(lambda x: cleaning_numbers(x))\n",
    "test['OriginalTweet'] = test['OriginalTweet'].apply(lambda x: cleaning_numbers(x))\n",
    "\n",
    "print('TRAIN DATA \\n', tweet['OriginalTweet'].head())\n",
    "print('\\n TEST DATA \\n', test['OriginalTweet'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T07:59:25.071861Z",
     "iopub.status.busy": "2022-01-19T07:59:25.071622Z",
     "iopub.status.idle": "2022-01-19T07:59:29.053118Z",
     "shell.execute_reply": "2022-01-19T07:59:29.052002Z",
     "shell.execute_reply.started": "2022-01-19T07:59:25.071832Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tokenize the OriginalTweet text\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer()\n",
    "tweet['Tokens'] = [tknzr.tokenize(t) for t in tweet['OriginalTweet']]\n",
    "tweet['Tokens'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T07:59:29.055137Z",
     "iopub.status.busy": "2022-01-19T07:59:29.054732Z",
     "iopub.status.idle": "2022-01-19T07:59:49.407616Z",
     "shell.execute_reply": "2022-01-19T07:59:49.406691Z",
     "shell.execute_reply.started": "2022-01-19T07:59:29.055094Z"
    }
   },
   "outputs": [],
   "source": [
    "st = nltk.PorterStemmer()\n",
    "def stemming_on_text(data):\n",
    "    text = [st.stem(word) for word in data]\n",
    "    return data\n",
    "tweet['Tokens']= tweet['Tokens'].apply(lambda x: stemming_on_text(x))\n",
    "tweet['Tokens'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T07:59:49.409981Z",
     "iopub.status.busy": "2022-01-19T07:59:49.409125Z",
     "iopub.status.idle": "2022-01-19T07:59:49.425846Z",
     "shell.execute_reply": "2022-01-19T07:59:49.425137Z",
     "shell.execute_reply.started": "2022-01-19T07:59:49.409943Z"
    }
   },
   "outputs": [],
   "source": [
    "stop_words = ['a',\n",
    " 'about',\n",
    " 'above',\n",
    " 'after',\n",
    " 'am',\n",
    " 'all',\n",
    "              'al',\n",
    "              \n",
    "              'an',\n",
    " 'and',\n",
    " 'any',\n",
    " 'are',\n",
    " 'as',\n",
    " 'at',\n",
    " 'be',\n",
    " 'because',\n",
    " 'been',\n",
    " 'before',\n",
    " 'being',\n",
    " 'below',\n",
    " 'between',\n",
    " 'but',\n",
    " 'by',\n",
    " 'could',\n",
    " 'did',\n",
    " 'do',\n",
    " 'does',\n",
    " 'doing',\n",
    " 'down',\n",
    " 'during',\n",
    " 'each',\n",
    " 'for',\n",
    " 'from',\n",
    " 'further',\n",
    " 'had',\n",
    " 'has',\n",
    " 'have',\n",
    " 'having',\n",
    " 'he',\n",
    " \"he'd\",\n",
    " \"he'll\",\n",
    " \"he's\",\n",
    " 'her',\n",
    " 'here',\n",
    " \"here's\",\n",
    " 'hers',\n",
    " 'herself',\n",
    " 'him',\n",
    " 'himself',\n",
    " 'his',\n",
    " 'how',\n",
    " \"how's\",\n",
    " 'i',\n",
    " \"i'd\",\n",
    " \"i'll\",\n",
    " \"i'm\",\n",
    " \"i've\",\n",
    " 'if',\n",
    " 'in',\n",
    " 'into',\n",
    " 'is',\n",
    " 'it',\n",
    " \"it's\",\n",
    " 'its',\n",
    " 'itself',\n",
    " \"let's\",\n",
    " 'me',\n",
    " 'my',\n",
    " 'myself',\n",
    " 'of',\n",
    " 'off',\n",
    " 'on',\n",
    " 'or',\n",
    " 'other',\n",
    " 'our',\n",
    " 'ours',\n",
    " 'ourselves',\n",
    " 'out',\n",
    " 'over',\n",
    " 'own',\n",
    " 'same',\n",
    " 'she',\n",
    " \"she'd\",\n",
    " \"she'll\",\n",
    " \"she's\",\n",
    " 'should',\n",
    " 'so',\n",
    " 'some',\n",
    " 'such',\n",
    " 'than',\n",
    " 'that',\n",
    " \"that's\",\n",
    " 'the',\n",
    " 'their',\n",
    " 'theirs',\n",
    " 'them',\n",
    " 'themselves',\n",
    " 'then',\n",
    " 'there',\n",
    " \"there's\",\n",
    " 'these',\n",
    " 'they',\n",
    " \"they'd\",\n",
    " \"they'll\",\n",
    " \"they're\",\n",
    " \"they've\",\n",
    " 'this',\n",
    " 'those',\n",
    " 'through',\n",
    " 'to',\n",
    " 'under',\n",
    " 'until',\n",
    " 'up',\n",
    " 'very',\n",
    " 'was',\n",
    " 'we',\n",
    " \"we'd\",\n",
    " \"we'll\",\n",
    " \"we're\",\n",
    " \"we've\",\n",
    " 'were',\n",
    " 'what',\n",
    " \"what's\",\n",
    " 'when',\n",
    " \"when's\",\n",
    " 'where',\n",
    " \"where's\",\n",
    " 'which',\n",
    " 'while',\n",
    " 'who',\n",
    " \"who's\",\n",
    " 'whom',\n",
    " 'why',\n",
    " \"why's\",\n",
    " 'with',\n",
    " \"won't\",\n",
    " 'would',\n",
    " 'you',\n",
    " \"you'd\",\n",
    " \"you'll\",\n",
    " \"you're\",\n",
    " \"you've\",\n",
    " 'your',\n",
    " 'yours',\n",
    " 'yourself',\n",
    " 'yourselves',\n",
    " \"that'll\",\n",
    " 's',\n",
    " 't',\n",
    " 'can',\n",
    " 'will',\n",
    " 'just',\n",
    " 'don',\n",
    " \"should've\",\n",
    " 'now',\n",
    " 'd',\n",
    " 'll',\n",
    " 'm',\n",
    " 'o',\n",
    " 're',\n",
    " 've',\n",
    " 'y',\n",
    " 'ma',\n",
    " 'across',\n",
    " 'im',\n",
    " 'l',\n",
    " 'shes',\n",
    " 'thatl',\n",
    " 'thatll',\n",
    " 'wil',\n",
    " 'youd',\n",
    " 'youl',\n",
    " 'youll',\n",
    " 'youre',\n",
    " 'youve']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T07:59:49.427188Z",
     "iopub.status.busy": "2022-01-19T07:59:49.426790Z",
     "iopub.status.idle": "2022-01-19T07:59:49.730729Z",
     "shell.execute_reply": "2022-01-19T07:59:49.729875Z",
     "shell.execute_reply.started": "2022-01-19T07:59:49.427160Z"
    }
   },
   "outputs": [],
   "source": [
    "STOPWORDS = set(stop_words)\n",
    "def cleaning_stopwords(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "tweet['OriginalTweet'] = tweet['OriginalTweet'].apply(lambda text: cleaning_stopwords(text))\n",
    "test['OriginalTweet'] = test['OriginalTweet'].apply(lambda text: cleaning_stopwords(text))\n",
    "\n",
    "print('TRAIN DATA \\n', tweet['OriginalTweet'].head())\n",
    "print('\\n TEST DATA \\n', test['OriginalTweet'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T07:59:49.733171Z",
     "iopub.status.busy": "2022-01-19T07:59:49.732249Z",
     "iopub.status.idle": "2022-01-19T07:59:52.246955Z",
     "shell.execute_reply": "2022-01-19T07:59:52.245979Z",
     "shell.execute_reply.started": "2022-01-19T07:59:49.733131Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tokenize the OriginalTweet text\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer()\n",
    "tweet['Tokens'] = [tknzr.tokenize(t) for t in tweet['OriginalTweet']]\n",
    "test['Tokens'] = [tknzr.tokenize(t) for t in test['OriginalTweet']]\n",
    "\n",
    "print('TRAIN DATA \\n', tweet['Tokens'].head())\n",
    "print('\\n TEST DATA \\n', test['Tokens'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T07:59:52.248870Z",
     "iopub.status.busy": "2022-01-19T07:59:52.248466Z",
     "iopub.status.idle": "2022-01-19T07:59:52.265444Z",
     "shell.execute_reply": "2022-01-19T07:59:52.264890Z",
     "shell.execute_reply.started": "2022-01-19T07:59:52.248820Z"
    }
   },
   "outputs": [],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "tag1 = nltk.pos_tag(tweet.iloc[20011,2])\n",
    "tag1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T07:59:52.267218Z",
     "iopub.status.busy": "2022-01-19T07:59:52.266607Z",
     "iopub.status.idle": "2022-01-19T07:59:55.515554Z",
     "shell.execute_reply": "2022-01-19T07:59:55.514632Z",
     "shell.execute_reply.started": "2022-01-19T07:59:52.267181Z"
    }
   },
   "outputs": [],
   "source": [
    "lm = nltk.stem.WordNetLemmatizer()\n",
    "def lemmatizer_on_text(data):\n",
    "    text = [lm.lemmatize(word) for word in data]\n",
    "    return data\n",
    "tweet['Tokens'] = tweet['Tokens'].apply(lambda x: lemmatizer_on_text(x))\n",
    "test['Tokens'] = test['Tokens'].apply(lambda x: lemmatizer_on_text(x))\n",
    "\n",
    "print('TRAIN DATA \\n', tweet['Tokens'].head())\n",
    "print('\\n TEST DATA \\n', test['Tokens'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T07:59:55.516878Z",
     "iopub.status.busy": "2022-01-19T07:59:55.516638Z",
     "iopub.status.idle": "2022-01-19T08:00:10.381097Z",
     "shell.execute_reply": "2022-01-19T08:00:10.380162Z",
     "shell.execute_reply.started": "2022-01-19T07:59:55.516848Z"
    }
   },
   "outputs": [],
   "source": [
    "st = nltk.PorterStemmer()\n",
    "def stemming_on_text(data):\n",
    "    text = [st.stem(word) for word in data]\n",
    "    return data\n",
    "tweet['Tokens']= tweet['Tokens'].apply(lambda x: stemming_on_text(x))\n",
    "tweet['Tokens'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T08:00:10.383113Z",
     "iopub.status.busy": "2022-01-19T08:00:10.382819Z",
     "iopub.status.idle": "2022-01-19T08:00:10.422627Z",
     "shell.execute_reply": "2022-01-19T08:00:10.421636Z",
     "shell.execute_reply.started": "2022-01-19T08:00:10.383082Z"
    }
   },
   "outputs": [],
   "source": [
    "tweet['text'] = tweet[\"Tokens\"].map(' '.join)\n",
    "test['text'] = test[\"Tokens\"].map(' '.join)\n",
    "\n",
    "print('TRAIN DATA \\n', tweet['text'].head())\n",
    "print('\\n TEST DATA \\n', test['text'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T08:00:10.424110Z",
     "iopub.status.busy": "2022-01-19T08:00:10.423890Z",
     "iopub.status.idle": "2022-01-19T08:00:10.642156Z",
     "shell.execute_reply": "2022-01-19T08:00:10.641113Z",
     "shell.execute_reply.started": "2022-01-19T08:00:10.424083Z"
    }
   },
   "outputs": [],
   "source": [
    "STOPWORDS = set(stop_words)\n",
    "def cleaning_stopwords(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "tweet['text'] = tweet['text'].apply(lambda text: cleaning_stopwords(text))\n",
    "test['text'] = test['text'].apply(lambda text: cleaning_stopwords(text))\n",
    "\n",
    "print('TRAIN DATA \\n', tweet['text'].head())\n",
    "print('\\n TEST DATA \\n', test['text'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T08:00:10.643798Z",
     "iopub.status.busy": "2022-01-19T08:00:10.643544Z",
     "iopub.status.idle": "2022-01-19T08:00:20.864179Z",
     "shell.execute_reply": "2022-01-19T08:00:20.863185Z",
     "shell.execute_reply.started": "2022-01-19T08:00:10.643765Z"
    }
   },
   "outputs": [],
   "source": [
    "#Adding dimensions with textblob\n",
    "#TextBlob Features\n",
    "from textblob import TextBlob\n",
    "\n",
    "def tb_enrich(ls):\n",
    "    #Enriches a column of text with TextBlob Sentiment Analysis outputs\n",
    "    tb_polarity = []\n",
    "    tb_subject = []\n",
    "\n",
    "    for tweet in ls:\n",
    "        sentiment = TextBlob(tweet).sentiment\n",
    "        tb_polarity.append(sentiment[0])\n",
    "        tb_subject.append(sentiment[1])\n",
    "    \n",
    "\n",
    "    return tb_polarity, tb_subject\n",
    "    \n",
    "tweet[\"Polarity\"], tweet[\"Subjectivity\"] = tb_enrich(list(tweet[\"text\"]))\n",
    "test[\"Polarity\"], test[\"Subjectivity\"] = tb_enrich(list(test[\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T08:00:20.865695Z",
     "iopub.status.busy": "2022-01-19T08:00:20.865444Z",
     "iopub.status.idle": "2022-01-19T08:00:20.897726Z",
     "shell.execute_reply": "2022-01-19T08:00:20.896850Z",
     "shell.execute_reply.started": "2022-01-19T08:00:20.865663Z"
    }
   },
   "outputs": [],
   "source": [
    "tweet.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T08:00:20.899377Z",
     "iopub.status.busy": "2022-01-19T08:00:20.899066Z",
     "iopub.status.idle": "2022-01-19T08:00:23.273492Z",
     "shell.execute_reply": "2022-01-19T08:00:23.272467Z",
     "shell.execute_reply.started": "2022-01-19T08:00:20.899344Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer  \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "X = tweet['text'] \n",
    "y = tweet['Sentiment']\n",
    "\n",
    "Count_vect = CountVectorizer(ngram_range=(1, 1), max_df=0.1, min_df=20)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.15, random_state = 42)\n",
    "Count_train = Count_vect.fit_transform(X_train).toarray()\n",
    "Count_test = Count_vect.transform(X_test).toarray()\n",
    "\n",
    "# Print the features\n",
    "print('# of feature names', len(Count_vect.get_feature_names()))\n",
    "print(Count_vect.get_feature_names()[99::100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T08:00:23.278915Z",
     "iopub.status.busy": "2022-01-19T08:00:23.278544Z",
     "iopub.status.idle": "2022-01-19T08:00:23.282475Z",
     "shell.execute_reply": "2022-01-19T08:00:23.281839Z",
     "shell.execute_reply.started": "2022-01-19T08:00:23.278861Z"
    }
   },
   "outputs": [],
   "source": [
    "# #Tokenisation\n",
    "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# #Define the Tokeniser\n",
    "# tokenizer = Tokenizer(num_words=3000, lower=True)\n",
    "\n",
    "# #Create the corpus by finding the most common \n",
    "# tokenizer.fit_on_texts(tweet[\"text\"])\n",
    "\n",
    "# ##Train\n",
    "# #Tokenise our column of edited Tweet content\n",
    "# tweet_tokens = tokenizer.texts_to_matrix(list(tweet[\"text\"]))\n",
    "\n",
    "# #Test\n",
    "# #Tokenise our column of edited Tweet content\n",
    "# tweet_tokens_test = tokenizer.texts_to_matrix(list(test[\"text\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T08:00:23.283919Z",
     "iopub.status.busy": "2022-01-19T08:00:23.283391Z",
     "iopub.status.idle": "2022-01-19T08:00:23.296818Z",
     "shell.execute_reply": "2022-01-19T08:00:23.295819Z",
     "shell.execute_reply.started": "2022-01-19T08:00:23.283878Z"
    }
   },
   "outputs": [],
   "source": [
    "#Combining the dataframe with the tokens using pd.concat\n",
    "\n",
    "#Reset axes to avoid overlapping\n",
    "# tweet.reset_index(drop=True, inplace=True)\n",
    "# test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "##Train\n",
    "# full_train = pd.concat([tweet[['Polarity', 'Subjectivity']], pd.DataFrame(tweet_tokens)], sort=False, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T08:00:23.298582Z",
     "iopub.status.busy": "2022-01-19T08:00:23.298272Z",
     "iopub.status.idle": "2022-01-19T08:00:23.308733Z",
     "shell.execute_reply": "2022-01-19T08:00:23.307955Z",
     "shell.execute_reply.started": "2022-01-19T08:00:23.298541Z"
    }
   },
   "outputs": [],
   "source": [
    "# full_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T08:00:23.310657Z",
     "iopub.status.busy": "2022-01-19T08:00:23.310139Z",
     "iopub.status.idle": "2022-01-19T08:00:23.322627Z",
     "shell.execute_reply": "2022-01-19T08:00:23.321429Z",
     "shell.execute_reply.started": "2022-01-19T08:00:23.310624Z"
    }
   },
   "outputs": [],
   "source": [
    "# ##Train\n",
    "# full_train2 = \n",
    "# full_train2.head()\n",
    "\n",
    "# full_test2 = \n",
    "# full_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T08:00:23.324963Z",
     "iopub.status.busy": "2022-01-19T08:00:23.324246Z",
     "iopub.status.idle": "2022-01-19T08:00:23.357311Z",
     "shell.execute_reply": "2022-01-19T08:00:23.356598Z",
     "shell.execute_reply.started": "2022-01-19T08:00:23.324913Z"
    }
   },
   "outputs": [],
   "source": [
    "#Define the indexing for each possible label in a dictionary\n",
    "class_to_index = {\"Neutral\":1, \"Positive\":2, \"Negative\":0,\"Extremely Negative\":0, \"Extremely Positive\": 2}\n",
    "\n",
    "#Creates a reverse dictionary\n",
    "index_to_class = {1: \"Neutral\", 2: \"Positive\", 0: \"Negative\"}\n",
    "\n",
    "#Creates lambda functions, applying the appropriate dictionary\n",
    "names_to_ids = lambda n: np.array([class_to_index.get(x) for x in n])\n",
    "ids_to_names = lambda n: np.array([index_to_class.get(x) for x in n])\n",
    "\n",
    "#Test each function\n",
    "print(names_to_ids([\"Extremely Positive\", \"Negative\", \"Positive\", \"Neutral\"]))\n",
    "print(ids_to_names([0,1,2]))\n",
    "\n",
    "\n",
    "#Convert the \"Sentiment\" column into indexes\n",
    "y_train_id = names_to_ids(y_train)\n",
    "y_test_id = names_to_ids(y_test)\n",
    "\n",
    "y_test_id[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T08:00:23.358963Z",
     "iopub.status.busy": "2022-01-19T08:00:23.358577Z",
     "iopub.status.idle": "2022-01-19T08:00:23.363520Z",
     "shell.execute_reply": "2022-01-19T08:00:23.362983Z",
     "shell.execute_reply.started": "2022-01-19T08:00:23.358926Z"
    }
   },
   "outputs": [],
   "source": [
    "y_test_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T08:00:23.364856Z",
     "iopub.status.busy": "2022-01-19T08:00:23.364602Z",
     "iopub.status.idle": "2022-01-19T08:00:25.403775Z",
     "shell.execute_reply": "2022-01-19T08:00:25.403066Z",
     "shell.execute_reply.started": "2022-01-19T08:00:23.364819Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "train_tf = tf.convert_to_tensor(Count_train)\n",
    "test_tf = tf.convert_to_tensor(Count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T08:00:25.404840Z",
     "iopub.status.busy": "2022-01-19T08:00:25.404618Z",
     "iopub.status.idle": "2022-01-19T08:00:25.419406Z",
     "shell.execute_reply": "2022-01-19T08:00:25.418588Z",
     "shell.execute_reply.started": "2022-01-19T08:00:25.404812Z"
    }
   },
   "outputs": [],
   "source": [
    "train_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.utils import class_weight\n",
    "# class_weights = class_weight.compute_class_weight('balanced',\n",
    "#                                                  np.unique(y_train_id),\n",
    "#                                                  y_train_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T08:29:05.059464Z",
     "iopub.status.busy": "2022-01-19T08:29:05.059176Z",
     "iopub.status.idle": "2022-01-19T08:29:05.109121Z",
     "shell.execute_reply": "2022-01-19T08:29:05.108296Z",
     "shell.execute_reply.started": "2022-01-19T08:29:05.059435Z"
    }
   },
   "outputs": [],
   "source": [
    "#Tensorflow / Keras\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(6, input_dim=3652, activation='relu'),\n",
    "    tf.keras.layers.Dense(9, activation='relu'),\n",
    "    #tf.keras.layers.Dense(50, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(9, activation='relu'),\n",
    "    #tf.keras.layers.Dense(50, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#Compile the model so it can be trained\n",
    "model.compile(\n",
    "     loss='sparse_categorical_crossentropy',\n",
    "     optimizer='adam',\n",
    "     metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T08:29:11.375044Z",
     "iopub.status.busy": "2022-01-19T08:29:11.372403Z",
     "iopub.status.idle": "2022-01-19T08:29:27.022714Z",
     "shell.execute_reply": "2022-01-19T08:29:27.022041Z",
     "shell.execute_reply.started": "2022-01-19T08:29:11.374992Z"
    }
   },
   "outputs": [],
   "source": [
    "h = model.fit(\n",
    "     train_tf, y_train_id, #class_weight=class_weights,\n",
    "     epochs=3,\n",
    "     callbacks=[tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=5)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T08:29:39.758477Z",
     "iopub.status.busy": "2022-01-19T08:29:39.757984Z",
     "iopub.status.idle": "2022-01-19T08:29:40.122321Z",
     "shell.execute_reply": "2022-01-19T08:29:40.121403Z",
     "shell.execute_reply.started": "2022-01-19T08:29:39.758429Z"
    }
   },
   "outputs": [],
   "source": [
    "#Generate predictions\n",
    "\n",
    "y_pred = np.argmax(model.predict(test_tf), axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_test_id, y_pred, normalize = 'true')\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_id, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T08:16:37.632926Z",
     "iopub.status.busy": "2022-01-19T08:16:37.632439Z",
     "iopub.status.idle": "2022-01-19T08:16:37.644720Z",
     "shell.execute_reply": "2022-01-19T08:16:37.644075Z",
     "shell.execute_reply.started": "2022-01-19T08:16:37.632881Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_labels = ids_to_names(y_pred)\n",
    "y_test_labels = ids_to_names(y_test_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T08:22:31.212809Z",
     "iopub.status.busy": "2022-01-19T08:22:31.212464Z",
     "iopub.status.idle": "2022-01-19T08:22:31.570799Z",
     "shell.execute_reply": "2022-01-19T08:22:31.569797Z",
     "shell.execute_reply.started": "2022-01-19T08:22:31.212776Z"
    }
   },
   "outputs": [],
   "source": [
    "y_unique = [\"Negative\", \"Neutral\", \"Positive\"]\n",
    "cm = confusion_matrix(y_test_labels, y_pred_labels, labels = y_unique, normalize='true')\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=y_unique)\n",
    "disp.plot(xticks_rotation='vertical',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from joblib import dump\n",
    "# dump(model, 'spam_classifier.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
