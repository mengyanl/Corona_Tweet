{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a853f227",
   "metadata": {},
   "source": [
    "# SpringBoard Capstone3: Coronavirus Tweets Sentiment Analysis\n",
    "\n",
    "    Data from Kaggle.com: https://www.kaggle.com/datatattle/covid-19-nlp-text-classification/metadata\n",
    "## XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da11a325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# from wordcloud import WordCloud\n",
    "import re\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c7fbd30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text         False\n",
       "Sentiment    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet = pd.read_csv('ProcessedTweets', index_col = 0)\n",
    "tweet.fillna('', inplace=True)\n",
    "tweet.head()\n",
    "tweet.isna().any()\n",
    "\n",
    "test = pd.read_csv('ProcessedTweets', index_col = 0)\n",
    "test.fillna('', inplace=True)\n",
    "test.head()\n",
    "test.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9456587f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of feature names 4507\n",
      "['alcoholbased', 'aldi', 'alegedly', 'alergies', 'alert', 'alive', 'almost', 'alone', 'along', 'alongside', 'alow', 'alowed', 'alowing', 'alows', 'already', 'also', 'alternative', 'alternatives', 'although', 'always', 'amazing', 'amazon', 'ambulance', 'america', 'american', 'americans', 'amid', 'amidst', 'amo', 'among', 'amongst', 'amount', 'amounts', 'amp', 'ample', 'analysis', 'analyst', 'analysts', 'analytics', 'andor', 'angela', 'angeles', 'angry', 'animal', 'animals', 'another', 'anounce', 'anounced', 'anouncement', 'anouncements', 'anounces', 'anouncing', 'answer', 'answered', 'answers', 'anti', 'antibacterial', 'anticipate', 'anual', 'anxiety', 'anxious', 'anybody', 'anymore', 'anyone', 'anything', 'anyway', 'anywhere', 'ap', 'aparel', 'aparently', 'apart', 'apartment', 'apeal', 'apear', 'apears', 'aple', 'aplications', 'aplied', 'aplies', 'aply', 'apocalypse', 'apr', 'apreciate', 'apreciated', 'apreciation', 'april', 'aproach', 'apropriate', 'aprove', 'aproved', 'aps', 'ar', 'arabia', 'area', 'areas', 'aren', 'arent', 'arest', 'arested', 'arive']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer  \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "X = tweet['text'] \n",
    "y = tweet['Sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.15, random_state = 42)\n",
    "\n",
    "Count_vect = CountVectorizer(ngram_range=(1, 1), max_df=0.7, min_df=15)\n",
    "\n",
    "Count_train = Count_vect.fit_transform(X_train)\n",
    "Count_test = Count_vect.transform(X_test)\n",
    "\n",
    "# Print the features\n",
    "print('# of feature names', len(Count_vect.get_feature_names()))\n",
    "print(Count_vect.get_feature_names()[100:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "52565985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.5.0-py3-none-macosx_10_14_x86_64.macosx_10_15_x86_64.macosx_11_0_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 2.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/Ling/opt/anaconda3/lib/python3.8/site-packages (from xgboost) (1.20.1)\n",
      "Requirement already satisfied: scipy in /Users/Ling/opt/anaconda3/lib/python3.8/site-packages (from xgboost) (1.6.2)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5de191a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 4 3 4 0]\n",
      "[3 0 4 4 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_XG = label_encoder.fit_transform(y_train)\n",
    "print(y_XG[:5])\n",
    "y_test_XG = label_encoder.fit_transform(y_test)\n",
    "print(y_test_XG[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62d36192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:33:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.50      0.56       790\n",
      "           1       0.72      0.55      0.62      1005\n",
      "           2       0.56      0.47      0.51      1516\n",
      "           3       0.55      0.84      0.67      1176\n",
      "           4       0.55      0.57      0.56      1687\n",
      "\n",
      "    accuracy                           0.58      6174\n",
      "   macro avg       0.60      0.59      0.58      6174\n",
      "weighted avg       0.59      0.58      0.58      6174\n",
      "\n",
      "Accuracy: 58.36%\n",
      "[[395  12 250  81  52]\n",
      " [  6 550  33  67 349]\n",
      " [164  41 711 322 278]\n",
      " [ 11  11  66 989  99]\n",
      " [ 47 149 206 327 958]]\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "XGmodel = XGBClassifier(use_label_encoder=False)\n",
    "XGmodel.fit(Count_train, y_XG)\n",
    "\n",
    "# make predictions for test data\n",
    "\n",
    "y_pred_XG = XGmodel.predict(Count_test)\n",
    "\n",
    "# evaluate predictions\n",
    "print(classification_report(y_test_XG, y_pred_XG))\n",
    "accuracy = accuracy_score(y_test_XG, y_pred_XG)\n",
    "CM_XG = confusion_matrix(y_test_XG, y_pred_XG)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "print(CM_XG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c5bd79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV 1/5; 1/4] START max_depth=10, n_estimators=20...............................\n",
      "[22:36:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/5; 1/4] END .............max_depth=10, n_estimators=20; total time=   7.6s\n",
      "[CV 2/5; 1/4] START max_depth=10, n_estimators=20...............................\n",
      "[22:36:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/5; 1/4] END .............max_depth=10, n_estimators=20; total time=   7.7s\n",
      "[CV 3/5; 1/4] START max_depth=10, n_estimators=20...............................\n",
      "[22:36:20] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/5; 1/4] END .............max_depth=10, n_estimators=20; total time=   7.5s\n",
      "[CV 4/5; 1/4] START max_depth=10, n_estimators=20...............................\n",
      "[22:36:27] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/5; 1/4] END .............max_depth=10, n_estimators=20; total time=   7.8s\n",
      "[CV 5/5; 1/4] START max_depth=10, n_estimators=20...............................\n",
      "[22:36:35] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/5; 1/4] END .............max_depth=10, n_estimators=20; total time=   7.5s\n",
      "[CV 1/5; 2/4] START max_depth=10, n_estimators=200..............................\n",
      "[22:36:43] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/5; 2/4] END ............max_depth=10, n_estimators=200; total time= 1.2min\n",
      "[CV 2/5; 2/4] START max_depth=10, n_estimators=200..............................\n",
      "[22:37:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/5; 2/4] END ............max_depth=10, n_estimators=200; total time= 1.2min\n",
      "[CV 3/5; 2/4] START max_depth=10, n_estimators=200..............................\n",
      "[22:39:08] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/5; 2/4] END ............max_depth=10, n_estimators=200; total time= 1.2min\n",
      "[CV 4/5; 2/4] START max_depth=10, n_estimators=200..............................\n",
      "[22:40:23] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/5; 2/4] END ............max_depth=10, n_estimators=200; total time= 1.3min\n",
      "[CV 5/5; 2/4] START max_depth=10, n_estimators=200..............................\n",
      "[22:41:42] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/5; 2/4] END ............max_depth=10, n_estimators=200; total time= 1.2min\n",
      "[CV 1/5; 3/4] START max_depth=50, n_estimators=20...............................\n",
      "[22:42:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/5; 3/4] END .............max_depth=50, n_estimators=20; total time=  38.7s\n",
      "[CV 2/5; 3/4] START max_depth=50, n_estimators=20...............................\n",
      "[22:43:33] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/5; 3/4] END .............max_depth=50, n_estimators=20; total time=  38.5s\n",
      "[CV 3/5; 3/4] START max_depth=50, n_estimators=20...............................\n",
      "[22:44:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/5; 3/4] END .............max_depth=50, n_estimators=20; total time=  38.6s\n",
      "[CV 4/5; 3/4] START max_depth=50, n_estimators=20...............................\n",
      "[22:44:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 4/5; 3/4] END .............max_depth=50, n_estimators=20; total time=  38.3s\n",
      "[CV 5/5; 3/4] START max_depth=50, n_estimators=20...............................\n",
      "[22:45:28] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/5; 3/4] END .............max_depth=50, n_estimators=20; total time=  38.7s\n",
      "[CV 1/5; 4/4] START max_depth=50, n_estimators=200..............................\n",
      "[22:46:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 1/5; 4/4] END ............max_depth=50, n_estimators=200; total time= 5.7min\n",
      "[CV 2/5; 4/4] START max_depth=50, n_estimators=200..............................\n",
      "[22:51:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 2/5; 4/4] END ............max_depth=50, n_estimators=200; total time= 4.4min\n",
      "[CV 3/5; 4/4] START max_depth=50, n_estimators=200..............................\n",
      "[22:56:18] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 3/5; 4/4] END ............max_depth=50, n_estimators=200; total time= 4.3min\n",
      "[CV 4/5; 4/4] START max_depth=50, n_estimators=200..............................\n",
      "[23:00:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 4/4] END ............max_depth=50, n_estimators=200; total time= 4.3min\n",
      "[CV 5/5; 4/4] START max_depth=50, n_estimators=200..............................\n",
      "[23:04:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV 5/5; 4/4] END ............max_depth=50, n_estimators=200; total time= 4.3min\n",
      "[23:09:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [20, 200],\n",
    "    #'colsample_bytree': [0.2, 0.8],\n",
    "    'max_depth': [10,50],\n",
    "    #'reg_alpha': [1.1, 1.3],\n",
    "    #'reg_lambda': [1.1, 1.3],\n",
    "    #'subsample': [0.5, 0.9]\n",
    "}\n",
    "\n",
    "grid_GX = GridSearchCV(XGBClassifier(use_label_encoder=False), param_grid=param_grid, cv = 5, scoring='accuracy', verbose=10)\n",
    "GX_grid_results = grid_GX.fit(Count_train,y_XG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "878aa853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.570562</td>\n",
       "      <td>0.087050</td>\n",
       "      <td>0.038165</td>\n",
       "      <td>0.003925</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 20}</td>\n",
       "      <td>0.500500</td>\n",
       "      <td>0.512220</td>\n",
       "      <td>0.518222</td>\n",
       "      <td>0.519297</td>\n",
       "      <td>0.524728</td>\n",
       "      <td>0.514993</td>\n",
       "      <td>0.008264</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73.185942</td>\n",
       "      <td>3.145271</td>\n",
       "      <td>0.768813</td>\n",
       "      <td>0.285830</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 200}</td>\n",
       "      <td>0.602687</td>\n",
       "      <td>0.607403</td>\n",
       "      <td>0.614120</td>\n",
       "      <td>0.619497</td>\n",
       "      <td>0.616924</td>\n",
       "      <td>0.612126</td>\n",
       "      <td>0.006209</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38.379387</td>\n",
       "      <td>0.124658</td>\n",
       "      <td>0.170928</td>\n",
       "      <td>0.002723</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 50, 'n_estimators': 20}</td>\n",
       "      <td>0.554095</td>\n",
       "      <td>0.557096</td>\n",
       "      <td>0.560955</td>\n",
       "      <td>0.568897</td>\n",
       "      <td>0.566038</td>\n",
       "      <td>0.561416</td>\n",
       "      <td>0.005474</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>274.072275</td>\n",
       "      <td>34.168977</td>\n",
       "      <td>2.022613</td>\n",
       "      <td>0.312483</td>\n",
       "      <td>50</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 50, 'n_estimators': 200}</td>\n",
       "      <td>0.597256</td>\n",
       "      <td>0.593969</td>\n",
       "      <td>0.604402</td>\n",
       "      <td>0.602773</td>\n",
       "      <td>0.607776</td>\n",
       "      <td>0.601235</td>\n",
       "      <td>0.004976</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       7.570562      0.087050         0.038165        0.003925   \n",
       "1      73.185942      3.145271         0.768813        0.285830   \n",
       "2      38.379387      0.124658         0.170928        0.002723   \n",
       "3     274.072275     34.168977         2.022613        0.312483   \n",
       "\n",
       "  param_max_depth param_n_estimators                                  params  \\\n",
       "0              10                 20   {'max_depth': 10, 'n_estimators': 20}   \n",
       "1              10                200  {'max_depth': 10, 'n_estimators': 200}   \n",
       "2              50                 20   {'max_depth': 50, 'n_estimators': 20}   \n",
       "3              50                200  {'max_depth': 50, 'n_estimators': 200}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           0.500500           0.512220           0.518222           0.519297   \n",
       "1           0.602687           0.607403           0.614120           0.619497   \n",
       "2           0.554095           0.557096           0.560955           0.568897   \n",
       "3           0.597256           0.593969           0.604402           0.602773   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           0.524728         0.514993        0.008264                4  \n",
       "1           0.616924         0.612126        0.006209                1  \n",
       "2           0.566038         0.561416        0.005474                3  \n",
       "3           0.607776         0.601235        0.004976                2  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=pd.DataFrame(grid_GX.cv_results_)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f115c920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:06:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.55      0.60       790\n",
      "           1       0.72      0.59      0.65      1005\n",
      "           2       0.59      0.54      0.57      1516\n",
      "           3       0.65      0.85      0.74      1176\n",
      "           4       0.58      0.61      0.60      1687\n",
      "\n",
      "    accuracy                           0.63      6174\n",
      "   macro avg       0.64      0.63      0.63      6174\n",
      "weighted avg       0.63      0.63      0.63      6174\n",
      "\n",
      "Accuracy: 62.96%\n",
      "[[ 436    9  256   46   43]\n",
      " [   8  592   27   29  349]\n",
      " [ 167   43  822  218  266]\n",
      " [  15    9   72 1000   80]\n",
      " [  36  166  209  239 1037]]\n"
     ]
    }
   ],
   "source": [
    "XGmodel = XGBClassifier(use_label_encoder=False, max_depth = 10, n_estimators = 200)\n",
    "XGmodel.fit(Count_train, y_XG)\n",
    "\n",
    "# make predictions for test data\n",
    "\n",
    "y_pred_XG = XGmodel.predict(Count_test)\n",
    "\n",
    "# evaluate predictions\n",
    "print(classification_report(y_test_XG, y_pred_XG))\n",
    "accuracy = accuracy_score(y_test_XG, y_pred_XG)\n",
    "CM_XG = confusion_matrix(y_test_XG, y_pred_XG)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "print(CM_XG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e00c84",
   "metadata": {},
   "source": [
    "## Did not do more steps, the XGboost is similar as SVC using tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098ba516",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
